{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 2\n",
    "## Desarrollo a)\n",
    "Las clases son 2: +1 y -1, que indican si un comentario es positivo o negativo.\n",
    "A continuación se muestra la cantidad de ejemplos que pertenece a cada clase en cada conjunto.\n",
    "<table>\n",
    "<tr><td></td><td>Clase +1</td><td>Clase -1</td>\n",
    "</tr>\n",
    "<tr> <td>Train Set</td><td>1784</td><td>1770</td>\n",
    "</tr>\n",
    "<tr> <td>Test Set</td><td>1803</td><td>1751</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3554, 2)\n",
      "(3554, 2)\n",
      "   Sentiment                                               Text\n",
      "0         -1  everything's serious , poetic , earnest and --...\n",
      "1         -1  narratively , trouble every day is a plodding ...\n",
      "2          1  a truly wonderful tale combined with stunning ...\n",
      "3          1  jason patric and ray liotta make for one splen...\n",
      "4         -1  haneke keeps us at arm's length . guided more ...\n",
      "5         -1  richard pryor mined his personal horrors and c...\n",
      "6         -1  puts on airs of a hal hartley wannabe film -- ...\n",
      "7         -1  the characters are interesting and the relatio...\n",
      "8         -1  this long and relentlessly saccharine film is ...\n",
      "9         -1  the movie's progression into rambling incohere...\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "train_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.train\"\n",
    "test_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.dev\"\n",
    "train_data_f = urllib.urlretrieve(train_data_url, \"train_data.csv\")\n",
    "test_data_f = urllib.urlretrieve(test_data_url, \"test_data.csv\")\n",
    "ftr = open(\"train_data.csv\", \"r\")\n",
    "fts = open(\"test_data.csv\", \"r\")\n",
    "rows = [line.split(\" \",1) for line in ftr.readlines()]\n",
    "train_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "train_df['Sentiment'] = pd.to_numeric(train_df['Sentiment'])\n",
    "rows = [line.split(\" \",1) for line in fts.readlines()]\n",
    "test_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "test_df['Sentiment'] = pd.to_numeric(test_df['Sentiment'])\n",
    "print train_df.shape\n",
    "print test_df.shape\n",
    "print train_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784 1770 3554\n",
      "1803 1751 3554\n"
     ]
    }
   ],
   "source": [
    "clase_pos = train_df.Sentiment.value_counts()[-1]\n",
    "clase_neg = train_df.Sentiment.value_counts()[1]\n",
    "print clase_pos, clase_neg, clase_pos + clase_neg\n",
    "\n",
    "clase_pos = test_df.Sentiment.value_counts()[-1]\n",
    "clase_neg = test_df.Sentiment.value_counts()[1]\n",
    "print clase_pos, clase_neg, clase_pos + clase_neg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo b)\n",
    "Se utilizará el stemming de porter.\n",
    "Al realizar stemming se observa que las palabras obtenidas están cortadas a lo que se espera sea su raíz. Por ejemplo, se observa que movie se transforma en movi luego del stemming, cuando movi no tiene ningún significado.\n",
    "Por otra parte running se transforma en run, esta transformación si es coherente. Pero como se ha visto no funcionan siempre los algoritmos de stemming.\n",
    "\n",
    "Al no realizar stemming las palabras quedan como aparecen, a excepción de las stopwords que son removidas por su poco aporte de significado en las frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love eat cake\n",
      " runner eat cake\n",
      " run eat cake\n",
      " love eat cake\n",
      " love eat cake\n",
      " love eat cake\n",
      " n't love eat cake\n",
      " holywood movi best\n",
      " resembl\n",
      " cat run ran cactu cactus cacti commun commun\n",
      " jump\n",
      " awaken\n",
      " bestrew\n"
     ]
    }
   ],
   "source": [
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "def word_extractor(text, Filter=True):\n",
    "    stemmer = PorterStemmer()\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ stemmer.stem(word.lower()) for word in word_tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "    \n",
    "    for word in wordtokens:\n",
    "        if Filter == True:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        else:\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "\n",
    "print word_extractor(\"I love to eat cake\")\n",
    "print word_extractor(\"I am a runner and eat cake\")\n",
    "print word_extractor(\"I am running and eat cake\")\n",
    "print word_extractor(\"I love eating cake\")\n",
    "print word_extractor(\"I loved eating the cake\")\n",
    "print word_extractor(\"I do not love eating cake\")\n",
    "print word_extractor(\"I don't love eating cake\")\n",
    "print word_extractor(\"holywood movies are the best\")\n",
    "print word_extractor(\"resembling\")\n",
    "print word_extractor(\"cats running ran cactus cactuses cacti community communities\")\n",
    "print word_extractor(\"jumping\")\n",
    "print word_extractor(\"awakened\")\n",
    "print word_extractor(\"bestrewed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo c)\n",
    "Se utiliza el lematizador WordNet. A diferencia del stemming la lematización utiliza una base de datos léxica, por lo que sus resultados son mejores, dado que analiza morfológicamente las palabras.\n",
    "\n",
    "Los resultados muestran que stemming realiza más transformaciones que la lematización, sin embargo stemming tiende a dejar formas sintácticas que no existen. Por ejemplo transforma resembling en resembl. Por otra parte, la lematización fue capaz de detectar la raíz de community y comminities como community, siendo que stemming cortó ambas palabras a \"commun\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love eat cake\n",
      " runner eat cake\n",
      " running eat cake\n",
      " love eating cake\n",
      " loved eating cake\n",
      " love eating cake\n",
      " n't love eating cake\n",
      " holywood movie best\n",
      " running sun\n",
      " love eat cake\n",
      " cat running ran cactus cactus cactus community community\n",
      " jumping\n",
      " resembling\n",
      " awakened\n",
      " bestrewed\n"
     ]
    }
   ],
   "source": [
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "\n",
    "def word_extractor2(text, Filter=True):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ wordlemmatizer.lemmatize(word.lower()) for word in word_tokenize(text.decode('utf-8','ignore')) ]\n",
    "    for word in wordtokens:\n",
    "        if Filter == True:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        else:\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "\n",
    "print word_extractor2(\"I love to eat cake\")\n",
    "print word_extractor2(\"I am a runner and eat cake\")\n",
    "print word_extractor2(\"I am running and eat cake\")\n",
    "print word_extractor2(\"I love eating cake\")\n",
    "print word_extractor2(\"I loved eating the cake\")\n",
    "print word_extractor2(\"I do not love eating cake\")\n",
    "print word_extractor2(\"I don't love eating cake\")\n",
    "print word_extractor2(\"holywood movies are the best\")\n",
    "print word_extractor2(\"I am running to the sun\")\n",
    "print word_extractor2(\"I love to eat cake\")\n",
    "print word_extractor2(\"cats running ran cactus cactuses cacti community communities\")\n",
    "print word_extractor2(\"jumping\")\n",
    "print word_extractor2(\"resembling\")\n",
    "print word_extractor2(\"awakened\")\n",
    "print word_extractor2(\"bestrewed\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo d)\n",
    "Son 9663 palabras en total se listarán el top 10 palabras según frecuencia.\n",
    "Las palabras para el conjunto de entrenamiento y validación son:\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-s6z2{text-align:center}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-hgcj{font-weight:bold;text-align:center}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-hgcj\">Frecuencia Train Set</th>\n",
    "    <th class=\"tg-hgcj\">Término Train Set</th>\n",
    "    <th class=\"tg-hgcj\">Frecuencia Test Set</th>\n",
    "    <th class=\"tg-hgcj\">Término Test Set</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">566</td>\n",
    "    <td class=\"tg-s6z2\">film</td>\n",
    "    <td class=\"tg-s6z2\">558</td>\n",
    "    <td class=\"tg-s6z2\">film</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">481</td>\n",
    "    <td class=\"tg-baqh\">movie</td>\n",
    "    <td class=\"tg-baqh\">540</td>\n",
    "    <td class=\"tg-baqh\">movie</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">246</td>\n",
    "    <td class=\"tg-baqh\">one</td>\n",
    "    <td class=\"tg-baqh\">250</td>\n",
    "    <td class=\"tg-baqh\">one</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">245</td>\n",
    "    <td class=\"tg-baqh\">like</td>\n",
    "    <td class=\"tg-baqh\">238</td>\n",
    "    <td class=\"tg-baqh\">ha</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">224</td>\n",
    "    <td class=\"tg-baqh\">ha</td>\n",
    "    <td class=\"tg-baqh\">230</td>\n",
    "    <td class=\"tg-baqh\">like</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">183</td>\n",
    "    <td class=\"tg-baqh\">make</td>\n",
    "    <td class=\"tg-baqh\">197</td>\n",
    "    <td class=\"tg-baqh\">story</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">176</td>\n",
    "    <td class=\"tg-baqh\">story</td>\n",
    "    <td class=\"tg-baqh\">175</td>\n",
    "    <td class=\"tg-baqh\">character</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">163</td>\n",
    "    <td class=\"tg-baqh\">character</td>\n",
    "    <td class=\"tg-baqh\">165</td>\n",
    "    <td class=\"tg-baqh\">time</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">145</td>\n",
    "    <td class=\"tg-baqh\">comedy</td>\n",
    "    <td class=\"tg-baqh\">161</td>\n",
    "    <td class=\"tg-baqh\">make</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">143</td>\n",
    "    <td class=\"tg-baqh\">time</td>\n",
    "    <td class=\"tg-baqh\">134</td>\n",
    "    <td class=\"tg-baqh\">comedy</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape:  (3554, 9663)\n",
      "labels train:  [ 0.  0.  1.  1.  0.  0.  0.  0.  0.  0.]\n",
      "Train:  9663\n",
      "Test:  9663\n",
      "566 film\n",
      "481 movie\n",
      "246 one\n",
      "245 like\n",
      "224 ha\n",
      "183 make\n",
      "176 story\n",
      "163 character\n",
      "145 comedy\n",
      "143 time\n",
      "558 film\n",
      "540 movie\n",
      "250 one\n",
      "238 ha\n",
      "230 like\n",
      "197 story\n",
      "175 character\n",
      "165 time\n",
      "161 make\n",
      "134 comedy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "print \"features.shape: \", features_train.shape\n",
    "\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "print \"labels train: \", labels_train[:10]\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "dist = list(np.array(features_train.sum(axis=0)).reshape(-1,))\n",
    "dist_test = list(np.array(features_test.sum(axis=0)).reshape(-1,))\n",
    "\n",
    "array = zip(dist, vocab)\n",
    "array.sort()\n",
    "array.reverse()\n",
    "\n",
    "array2 = zip(dist_test, vocab)\n",
    "array2.sort()\n",
    "array2.reverse()\n",
    "\n",
    "print \"Train: \", len(array)\n",
    "print \"Test: \", len(array2)\n",
    "\n",
    "for count, tag in array[:10]:\n",
    "    print count, tag\n",
    "for count, tag in array2[:10]:\n",
    "    print count, tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo e)\n",
    "Las métricas que son entregadas por classification_report son: precision, recall, f1-score y support.\n",
    "<li>precision: Se calcula como tp/(tp+fp), lo que indica la habilidad del clasificador para no etiquetar como positivo una muestra que es negativa. (tp: true positive. fp: false positive).</li>\n",
    "<li>recall: Se calcula como tp/(tp+fn). Es la habilidad del clasificador para encontrar todas las muestras positivas. (fn:false negative).</li>\n",
    "<li>f1-score: Se calcula como 2*(precision*recall)/(precision+recall). Se interpreta como un promedio ponderado de la precision y recall. El mejor valor es 1 y corresponde cuando la contribución de precision y recall es igual. El peor caso es 0.</li>\n",
    "<li>support: Corresponde al número de ocurrencias de cada clase en los ejemplos correctamente clasificados como positivos.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def score_the_model(model,x,y,xt,yt,text):\n",
    "    acc_tr = model.score(x,y)\n",
    "    acc_test = model.score(xt[:-1],yt[:-1])\n",
    "    print \"Training Accuracy %s: %f\"%(text,acc_tr)\n",
    "    print \"Test Accuracy %s: %f\"%(text,acc_test)\n",
    "    print \"Detailed Analysis Testing Results ...\"\n",
    "    print(classification_report(yt, model.predict(xt), target_names=['+','-']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo f)\n",
    "\n",
    "1. Construya una función que entrene/ajuste un clasificador Bayesiano Ingenuo (Binario) (las carac-\n",
    "terı́sticas no nulas serán tratadas como 1) y \n",
    "1.1 mida el error de predicción obtenido sobre los datos de entrenamiento y pruebas.Utilice esta función con las caracterı́sticas extraı́das en el punto (d).\n",
    "\n",
    "2. Mida el efecto de filtrar stopwords y de eliminar este paso de pre-procesamiento tı́pico. \n",
    "\n",
    "\n",
    "3. qué representación obtiene un mejor resultado: lematización o stemming.\n",
    "4. Finalmente, tome un subconjunto aleatorio de los textos de prueba y analice las predic-\n",
    "ciones del modelo (explore las predicciones, ası́ como las probabilidades que el clasificador asigna a cada\n",
    "clase).\n",
    "\n",
    "\n",
    "Al entrenar un clasificador bayesiano ingenuo, se obtiene una precisión de 95,86% en los datos de entrenamiento y un 73,85% en los datos de prueba.\n",
    "Se utilizan los datos tal como fueron preprocesados en la pregunta 1.d), considerando que se realizó lematización y eliminación de stopwords antes de entrenar el modelo.\n",
    "\n",
    "Al entrenar sin realizar la eliminación de las stopwords, la predicción de entrenamiento decae a 95,52%, pero la predicción en los datos de prueba aumenta a 74,86%.\n",
    "\n",
    "\n",
    "Realizando las mismas pruebas anteriores, pero ahora utilizando stemming, se tiene lo siguiente:\n",
    "<li>Naive Bayes + Stemming + Remoción de Stopwords:\n",
    "<center><li>Precisión con los datos de entrenamiento: 94,28%</li><li>Precisión con los datos de pruebas: 74,78%</li></center>\n",
    "</li>\n",
    "<li>Relizando Naive Bayes + Stemming:\n",
    "<center><li>Precisión con los datos de entrenamiento: 93,80%</li><li>Precisión con los datos de pruebas: 76,21%</li></center>\n",
    "</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.958638\n",
      "Test Accuracy BernoulliNB: 0.738531\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "[ 0.97957118  0.02042882] a decidedly mixed bag .\n",
      "\n",
      "[ 0.56471363  0.43528637] those who want to be jolted out of their gourd should drop e\n",
      "[ 0.95558611  0.04441389] just too silly and sophomoric to ensnare its target audience\n",
      "[ 0.78506042  0.21493958] an empty , ugly exercise in druggy trance-noir and trumped-u\n",
      "[ 0.90934363  0.09065637] comes across as a fairly weak retooling .\n",
      "\n",
      "[ 0.40455023  0.59544977] enticing and often funny documentary .\n",
      "\n",
      "[ 0.87641789  0.12358211] culkin turns his character into what is basically an anti-ha\n",
      "[ 0.97859373  0.02140627] toward the end sum of all fears morphs into a mundane '70s d\n",
      "[ 0.53151912  0.46848088] some movies suck you in despite their flaws , and heaven is \n",
      "[ 0.98030108  0.01969892] the reason i found myself finally unmoved by this film , whi\n",
      "[  6.58707280e-04   9.99341293e-01] drumline ably captures the complicated relationships in a ma\n",
      "[ 0.44745863  0.55254137] it's as if solondz had two ideas for two movies , couldn't r\n",
      "[ 0.71294958  0.28705042] trades run-of-the-mill revulsion for extreme unease .\n",
      "\n",
      "[ 0.19809868  0.80190132] the film has several strong performances .\n",
      "\n",
      "[ 0.78023455  0.21976545] any enjoyment will be hinge from a personal threshold of wat\n"
     ]
    }
   ],
   "source": [
    "# 1. naive bayes con lematización y extracción de stopwords.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import random\n",
    "\n",
    "def do_NAIVE_BAYES(x,y,xt,yt):\n",
    "    model = BernoulliNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"BernoulliNB\")\n",
    "    return model\n",
    "\n",
    "model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text[:60]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.955262\n",
      "Test Accuracy BernoulliNB: 0.748663\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.74      0.75      1803\n",
      "          -       0.74      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "[ 0.08667367  0.91332633] ( rises ) above its oh-so-hollywood rejiggering and its conv\n",
      "[ 0.89432297  0.10567703] gets bogged down by an overly sillified plot and stop-and-st\n",
      "[ 0.11064803  0.88935197] eight legged freaks won't join the pantheon of great monster\n",
      "[ 0.23989139  0.76010861] fancy a real downer ? [leigh] lays it on so thick this time \n",
      "[ 0.98344459  0.01655541] despite the fact that this film wasn't as bad as i thought i\n",
      "[ 0.9695741  0.0304259] it's fitting that a movie as artificial and soulless as the \n",
      "[ 0.53758227  0.46241773] a limp eddie murphy vehicle that even he seems embarrassed t\n",
      "[ 0.01046034  0.98953966] a quietly moving look back at what it was to be iranian-amer\n",
      "[ 0.06603737  0.93396263] shyamalan takes a potentially trite and overused concept ( a\n",
      "[ 0.96815871  0.03184129] maybe you'll be lucky , and there'll be a power outage durin\n",
      "[ 0.52436252  0.47563748] [gai] comes closer to any actress i can remember to personif\n",
      "[ 0.01066504  0.98933496] this film is an act of spiritual faith -- an eloquent , deep\n",
      "[ 0.07452041  0.92547959] its maker , steven spielberg , hasn't had so much fun in two\n",
      "[ 0.95938705  0.04061295] \" . . . something appears to have been lost in the translati\n",
      "[ 0.44099181  0.55900819] the story of trouble every day . . . is so sketchy it amount\n"
     ]
    }
   ],
   "source": [
    "'''def word_extractor3(text):\n",
    "    # Pasa a minúsculas y extrae.\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ word.lower() for word in word_tokenize(text.decode('utf-8','ignore')) ]\n",
    "    for word in wordtokens:\n",
    "        words+=\" \"+word\n",
    "    return words\n",
    "\n",
    "print word_extractor3(\"I love to eat cake\")\n",
    "print word_extractor3(\"I am a runner and eat cake\")\n",
    "print word_extractor3(\"I am running and eat cake\")\n",
    "'''\n",
    "# 2. Modelo Naive Bayes con datos sin remoción de stopwords.\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts_train = [word_extractor2(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text, False) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "#labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "#labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "\n",
    "model = do_NAIVE_BAYES(features_train, labels_train, features_test, labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.942881\n",
      "Test Accuracy BernoulliNB: 0.747819\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.74      0.75      1803\n",
      "          -       0.74      0.75      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "[1023, 3275, 2407, 2148, 3369, 3098, 299, 3309, 2477, 990, 2849, 2435, 2498, 1843, 1628]\n",
      "[ 0.22972082  0.77027918] highlighted by a gritty style and an excellent cast , it's b\n",
      "[ 0.89119144  0.10880856] when a movie has stuck around for this long , you know there\n",
      "[ 0.62170806  0.37829194] there's an audience for it , but it could have been funnier \n",
      "[ 0.73789501  0.26210499] like mike is a slight and uninventive movie : like the exalt\n",
      "[ 0.93924639  0.06075361] collateral damage is , despite its alleged provocation post-\n",
      "[  9.99340097e-01   6.59903220e-04] at every opportunity to do something clever , the film goes \n",
      "[ 0.44658419  0.55341581] �the maudlin way its story unfolds suggests a director fight\n",
      "[ 0.79457628  0.20542372] the limited sets and small confined and dark spaces also are\n",
      "[ 0.17368279  0.82631721] narc is a no-bull throwback to 1970s action films . it zips \n",
      "[ 0.23562022  0.76437978] the ch�teau would have been benefited from a sharper , clean\n",
      "[ 0.00585727  0.99414273] [stephen] earnhart's film is more about the optimism of a gr\n",
      "[ 0.1026651  0.8973349] an overstylized , pur�ed m�lange of sex , psychology , drugs\n",
      "[ 0.16101798  0.83898202] the chateau is a risky venture that never quite goes where y\n",
      "[ 0.55308014  0.44691986] appropriately cynical social commentary aside , #9 never qui\n",
      "[ 0.69614793  0.30385207] it's an awfully derivative story .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Naive Bayes Stemming y remoción de Stopwords.\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts_train = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "#labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "#labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "\n",
    "model = do_NAIVE_BAYES(features_train, labels_train, features_test, labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.938098\n",
      "Test Accuracy BernoulliNB: 0.762173\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.77      0.76      0.77      1803\n",
      "          -       0.76      0.76      0.76      1751\n",
      "\n",
      "avg / total       0.76      0.76      0.76      3554\n",
      "\n",
      "[ 0.41646436  0.58353564] the origin story is well told , and the characters will not disappoint anyone who values the original comic books . it's in the action scenes that things fall apart .\n",
      "\n",
      "[ 0.09168777  0.90831223] sweet and memorable film .\n",
      "\n",
      "[ 0.98048195  0.01951805] it has the air of a surprisingly juvenile lark , a pop-influenced prank whose charms are immediately apparent and wear thin with repetition .\n",
      "\n",
      "[ 0.95461696  0.04538304] this horror-comedy doesn't go for the usual obvious laughs at the expense of cheap-looking monsters -- unless you count elvira's hooters .\n",
      "\n",
      "[ 0.4098698  0.5901302] it's excessively quirky and a little underconfident in its delivery , but otherwise this is the best 'old neighborhood' project since christopher walken kinda romanced cyndi lauper in the opportunists .\n",
      "\n",
      "[  9.99735981e-01   2.64018937e-04] whether it's the worst movie of 2002 , i can't say for sure : memories of rollerball have faded , and i skipped country bears . but this new jangle of noise , mayhem and stupidity must be a serious contender for the title .\n",
      "\n",
      "[ 0.31670025  0.68329975] from the big giant titles of the opening credits to elmer bernstein's perfectly melodic score , haynes gets just about everything right .\n",
      "\n",
      "[ 0.89361545  0.10638455] one groan-inducing familiarity begets another .\n",
      "\n",
      "[ 0.39137576  0.60862424] a trashy , exploitative , thoroughly unpleasant experience .\n",
      "\n",
      "[ 0.8277457  0.1722543] it's lost the politics and the social observation and become just another situation romance about a couple of saps stuck in an inarticulate screenplay .\n",
      "\n",
      "[ 0.93058634  0.06941366] the sweetest thing leaves a bitter taste .\n",
      "\n",
      "[ 0.30628453  0.69371547] whatever the movie's sentimental , hypocritical lessons about sexism , its true colors come out in various wet t-shirt and shower scenes .\n",
      "\n",
      "[ 0.27978087  0.72021913] the emperor's club is one of those films that possesses all the good intentions in the world , but . . .\n",
      "\n",
      "[  6.35172366e-04   9.99364828e-01] a fascinating documentary about the long and eventful spiritual journey of the guru who helped launch the new age .\n",
      "\n",
      "[ 0.31526067  0.68473933] contrasting the original ringu with the current americanized adaptation is akin to comparing the evil dead with evil dead ii\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Naive Bayes Stemming sin remoción de stopwords.\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts_train = [word_extractor(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor(text, False) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "model = do_NAIVE_BAYES(features_train, labels_train, features_test, labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo g)\n",
    "A continuación se realiza el entrenamiento de un clasificador bayesiano multinomial variando el preprocesamiento de los datos.\n",
    "A continuación se detallarán los experimentos realizados:\n",
    "<li>Multinomial Naive Bayes + lemmatization + remoción Stopwords:\n",
    "<center>\n",
    "<li>Train Set Precision: 95,94%</li>\n",
    "<li>Test Set Precision: 74,07%</li>\n",
    "</center>\n",
    "</li>\n",
    "\n",
    "<li>Multinomial Naive Bayes + lemmatization sin remoción Stopwords:\n",
    "<center>\n",
    "<li>Train Set Precision: 95,55%</li>\n",
    "<li>Test Set Precision: 74,75%</li>\n",
    "</center>\n",
    "</li>\n",
    "\n",
    "<li>Multinomial Naive Bayes + Stemming + remoción Stopwords:\n",
    "<center>\n",
    "<li>Train Set Precision: 94,93%</li>\n",
    "<li>Test Set Precision: 74,97%</li>\n",
    "</center>\n",
    "</li>\n",
    "\n",
    "<li>Multinomial Naive Bayes + Stemming sin remoción Stopwords:\n",
    "<center>\n",
    "<li>Train Set Precision: 94,06%</li>\n",
    "<li>Test Set Precision: 75,99%</li>\n",
    "</center>\n",
    "</li>\n",
    "\n",
    "Se observa que los mejores resultados se presentan al combinar Multinomial Naive Bayes + Stemming sin remover las Stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.959482\n",
      "Test Accuracy MULTINOMIAL: 0.740782\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "[ 0.13871231  0.86128769] while the story's undeniably hard to follow , iwai's gorgeous visuals seduce .\n",
      "\n",
      "[ 0.07945105  0.92054895] it is intensely personal and yet -- unlike quills -- deftly shows us the temper of the times .\n",
      "\n",
      "[ 0.25627327  0.74372673] if the last man were the last movie left on earth , there would be a toss-up between presiding over the end of cinema as we know it and another night of delightful hand shadows .\n",
      "\n",
      "[ 0.06465761  0.93534239] y tu mam� tambi�n es un buen filme gracias a lo poco convencional de su narrativa , y es quiz� el proyecto m�s arriesgado en la carrera de alfonso cuar�n\n",
      "\n",
      "[ 0.00559586  0.99440414] a rock-solid gangster movie with a fair amount of suspense , intriguing characters and bizarre bank robberies , plus a heavy dose of father-and-son dynamics .\n",
      "\n",
      "[ 0.51123697  0.48876303] i like this movie a lot . i like that smith , he's not making fun of these people , he's not laughing at them .\n",
      "\n",
      "[ 0.96186633  0.03813367] heavy-handed exercise in time-vaulting literary pretension .\n",
      "\n",
      "[ 0.7651984  0.2348016] a muddy psychological thriller rife with miscalculations . it makes me say the obvious : abandon all hope of a good movie ye who enter here .\n",
      "\n",
      "[ 0.13413528  0.86586472] while the frequent allusions to gurus and doshas will strike some westerners as verging on mumbo-jumbo . . . broad streaks of common sense emerge with unimpeachable clarity .\n",
      "\n",
      "[ 0.78921281  0.21078719] the characters are so generic and the plot so bland that even as rogue cia assassins working for chris cooper's agency boss close in on the resourceful amnesiac , we don't feel much for damon/bourne or his predicament .\n",
      "\n",
      "[ 0.28595096  0.71404904] you come away from his film overwhelmed , hopeful and , perhaps paradoxically , illuminated .\n",
      "\n",
      "[ 0.32781892  0.67218108] yo , it's the days of our lives meets electric boogaloo .\n",
      "\n",
      "[ 0.00302655  0.99697345] while certain cues , like the happy music , suggest that this movie is supposed to warm our hearts , jeong-hyang lee's film is just as likely to blacken that organ with cold vengefulness .\n",
      "\n",
      "[ 0.24391816  0.75608184] to portray modern women the way director davis has done is just unthinkable .\n",
      "\n",
      "[ 0.54971187  0.45028813] es divertida , visualmente espectacular y muy entretenida . simple y sencillamente te sorprender� .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Multinomial + lemmatization + remoción Stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import random\n",
    "\n",
    "def do_MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"MULTINOMIAL\")\n",
    "    return model\n",
    "\n",
    "\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.955543\n",
      "Test Accuracy MULTINOMIAL: 0.747537\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.75      0.75      1803\n",
      "          -       0.74      0.74      0.74      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "[ 0.8339219  0.1660781] take away all the cliches and the carbon copy scenes from every drug movie we've seen and all you have left are john leguizamo's cool jackets .\n",
      "\n",
      "[ 0.32075654  0.67924346] like any good romance , son of the bride , proves it's never too late to learn .\n",
      "\n",
      "[ 0.0822181  0.9177819] slight but enjoyable documentary .\n",
      "\n",
      "[ 0.7704261  0.2295739] with a story as bizarre and mysterious as this , you don't want to be worrying about whether the ineffectual broomfield is going to have the courage to knock on that door .\n",
      "\n",
      "[ 0.00486512  0.99513488] bravo for history rewritten , and for the uncompromising knowledge that the highest power of all is the power of love .\n",
      "\n",
      "[ 0.97132789  0.02867211] wasabi is slight fare indeed , with the entire project having the feel of something tossed off quickly ( like one of hubert's punches ) , but it should go down smoothly enough with popcorn .\n",
      "\n",
      "[ 0.12991173  0.87008827] longley has constructed a remarkably coherent , horrifically vivid snapshot of those turbulent days .\n",
      "\n",
      "[  9.99434978e-01   5.65021769e-04] myers never knows when to let a gag die ; thus , we're subjected to one mind-numbingly lengthy riff on poo and pee jokes after another .\n",
      "\n",
      "[ 0.84319367  0.15680633] an intermittently pleasing but mostly routine effort .\n",
      "\n",
      "[ 0.57840005  0.42159995] if you can swallow its absurdities and crudities lagaan really is enormously good fun .\n",
      "\n",
      "[  9.99311531e-01   6.88468921e-04] essentially \" fatal attraction \" remade for viewers who were in diapers when the original was released in 1987 . . . . this story gets sillier , not scarier , as it goes along . . .\n",
      "\n",
      "[ 0.10971462  0.89028538] must be seen to be believed .\n",
      "\n",
      "[ 0.50782025  0.49217975] even a hardened voyeur would require the patience of job to get through this interminable , shapeless documentary about the swinging subculture .\n",
      "\n",
      "[ 0.08005563  0.91994437] . . . a triumph of emotionally and narratively complex filmmaking .\n",
      "\n",
      "[ 0.4113308  0.5886692] a real audience-pleaser that will strike a chord with anyone who's ever waited in a doctor's office , emergency room , hospital bed or insurance company office .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Multinomial + lemmatization sin remoción Stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import random\n",
    "\n",
    "def do_MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"MULTINOMIAL\")\n",
    "    return model\n",
    "\n",
    "\n",
    "texts_train = [word_extractor2(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text, False) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.942319\n",
      "Test Accuracy MULTINOMIAL: 0.749789\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.75      0.75      1803\n",
      "          -       0.74      0.75      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "[ 0.46483611  0.53516389] huston nails both the glad-handing and the choking sense of hollow despair .\n",
      "\n",
      "[ 0.06694084  0.93305916] ub equally spoofs and celebrates the more outre aspects of 'black culture' and the dorkier aspects of 'white culture , ' even as it points out how inseparable the two are .\n",
      "\n",
      "[ 0.10151959  0.89848041] 13 conversations may be a bit too enigmatic and overly ambitious to be fully successful , but sprecher and her screenwriting partner and sister , karen sprecher , don't seem ever to run out of ideas .\n",
      "\n",
      "[ 0.18992494  0.81007506] 'estupendamente actuada , sumamente emotiva y profundamente humana , es una experiencia f�lmica imposible de olvidar'\n",
      "\n",
      "[  6.97213025e-04   9.99302787e-01] a tough go , but leigh's depth and rigor , and his skill at inspiring accomplished portrayals that are all the more impressive for their lack of showiness , offsets to a notable degree the film's often-mined and despairing milieu .\n",
      "\n",
      "[ 0.20473486  0.79526514] shyamalan takes a potentially trite and overused concept ( aliens come to earth ) and infuses it into a rustic , realistic , and altogether creepy tale of hidden invasion .\n",
      "\n",
      "[ 0.87678945  0.12321055] one can't deny its seriousness and quality .\n",
      "\n",
      "[ 0.05588832  0.94411168] from spiritual rebirth to bruising defeat , vincent's odyssey resonates in a profound way , comparable to the classic films of jean renoir .\n",
      "\n",
      "[ 0.98425849  0.01574151] a sour attempt at making a farrelly brothers-style , down-and-dirty laugher for the female set .\n",
      "\n",
      "[ 0.82945635  0.17054365] a great idea becomes a not-great movie .\n",
      "\n",
      "[ 0.01648929  0.98351071] if this story must be told and retold -- and indeed it must -- then the grey zone is to be lauded for finding a new and ingenious angle .\n",
      "\n",
      "[ 0.02919793  0.97080207] beautifully crafted and cooly unsettling . . . recreates the atmosphere of the crime expertly .\n",
      "\n",
      "[ 0.038594  0.961406] surprisingly powerful and universal .\n",
      "\n",
      "[ 0.00378969  0.99621031] an exciting and involving rock music doc , a smart and satisfying look inside that tumultuous world .\n",
      "\n",
      "[ 0.84052495  0.15947505] scarlet diva has a voyeuristic tug , but all in all it's a lot less sensational than it wants to be .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Multinomial + Stemming + remoción Stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import random\n",
    "\n",
    "def do_MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"MULTINOMIAL\")\n",
    "    return model\n",
    "\n",
    "\n",
    "texts_train = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.940630\n",
      "Test Accuracy MULTINOMIAL: 0.759921\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.77      0.76      1803\n",
      "          -       0.76      0.75      0.76      1751\n",
      "\n",
      "avg / total       0.76      0.76      0.76      3554\n",
      "\n",
      "[ 0.39693867  0.60306133] wanders all over the map thematically and stylistically , and borrows heavily from lynch , jeunet , and von trier while failing to find a spark of its own .\n",
      "\n",
      "[ 0.57601009  0.42398991] boy , has this franchise ever run out of gas .\n",
      "\n",
      "[ 0.00373353  0.99626647] shanghai ghetto may not be as dramatic as roman polanski's the pianist , but its compassionate spirit soars every bit as high .\n",
      "\n",
      "[ 0.06189377  0.93810623] 'almod�var logra un filme entra�able , lleno de compasi�n , comprensi�n , amor , amistad , esperanza y humanidad que es sencillamente inolvidable . '\n",
      "\n",
      "[ 0.99359632  0.00640368] [sen's] soap opera-ish approach undermines his good intentions .\n",
      "\n",
      "[ 0.99808134  0.00191866] a pathetic exploitation film that tries to seem sincere , and just seems worse for the effort .\n",
      "\n",
      "[ 0.06118365  0.93881635] a strong first act and absolutely , inescapably gorgeous , skyscraper-trapeze motion of the amazing spider-man .\n",
      "\n",
      "[ 0.31352539  0.68647461] real women have curves wears its empowerment on its sleeve but even its worst harangues are easy to swallow thanks to remarkable performances by ferrera and ontiveros .\n",
      "\n",
      "[ 0.0801429  0.9198571] a buoyant romantic comedy about friendship , love , and the truth that we're all in this together .\n",
      "\n",
      "[ 0.48122775  0.51877225] we started to wonder if � some unpaid intern had just typed 'chris rock , ' 'anthony hopkins' and 'terrorists' into some univac-like script machine .\n",
      "\n",
      "[ 0.90273463  0.09726537] the writers , director wally wolodarsky , and all the actors should start their own coeducational fraternity : kappa rho alpha phi .\n",
      "\n",
      "[ 0.03918399  0.96081601] k-19 : the widowmaker is derivative , overlong , and bombastic -- yet surprisingly entertaining .\n",
      "\n",
      "[ 0.00564794  0.99435206] the artwork is spectacular and unlike most animaton from japan , the characters move with grace and panache .\n",
      "\n",
      "[ 0.9987152  0.0012848] oops , she's really done it this time . that chirpy songbird britney spears has popped up with more mindless drivel .\n",
      "\n",
      "[ 0.72818811  0.27181189] an entertaining mix of period drama and flat-out farce that should please history fans .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Multinomial + Stemming sin remoción Stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import random\n",
    "\n",
    "def do_MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"MULTINOMIAL\")\n",
    "    return model\n",
    "\n",
    "\n",
    "texts_train = [word_extractor(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor(text, False) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 15)\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo h)\n",
    "A continuación se realiza el entrenamiento de un clasificador utilizando regresión logística. Además se varía el preprocesamiento de los datos.\n",
    "\n",
    "A continuación se detallarán los experimentos realizados y se mostrarán los **mejores** resultados obtenidos para cada experimento según el parámetro de regularización.\n",
    "<center>\n",
    "<li>Logistic Regression + lemmatization + remoción Stopwords + Parámetro de regularización = 0.1:\n",
    "<center>\n",
    "Train Set Precision: 89,92%<br>\n",
    "Test Set Precision: 71,91%\n",
    "</center>\n",
    "</li><br>\n",
    "\n",
    "<li>Logistic Regression + lemmatization sin remoción Stopwords + Parámetro de regularización = 10.0:\n",
    "<center>\n",
    "Train Set Precision: 100%<br>\n",
    "Test Set Precision: 73,14%\n",
    "</center>\n",
    "</li><br>\n",
    "\n",
    "<li>Logistic Regression + Stemming + remoción Stopwords + Parámetro de regularización = 10.0:\n",
    "<center>\n",
    "Train Set Precision: 88,01%<br>\n",
    "Test Set Precision: 73,12%\n",
    "</center>\n",
    "</li><br>\n",
    "\n",
    "<li>Logistic Regression + Stemming sin remoción Stopwords + Parámetro de regularización = 0.1:\n",
    "<center>\n",
    "Train Set Precision: 100%<br>\n",
    "Test Set Precision: 73,59%\n",
    "</center>\n",
    "</li>\n",
    "</center>\n",
    "\n",
    "# Explicación parámetro L2!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.784468\n",
      "Test Accuracy LOGISTIC: 0.678863\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.67      0.73      0.70      1803\n",
      "          -       0.69      0.63      0.66      1751\n",
      "\n",
      "avg / total       0.68      0.68      0.68      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.892234\n",
      "Test Accuracy LOGISTIC: 0.719111\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.72      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.718548\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.714044\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.71      0.72      1803\n",
      "          -       0.71      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.712356\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.71      0.71      1803\n",
      "          -       0.70      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression + Lemmatization + remoción Stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def do_LOGIT(x,y,xt,yt):\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"Usando C= %f\"%C\n",
    "        model = LogisticRegression(penalty='l2',C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"LOGISTIC\")\n",
    "\n",
    "    \n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.734102\n",
      "Test Accuracy LOGISTIC: 0.671827\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.68      0.68      0.68      1803\n",
      "          -       0.67      0.66      0.67      1751\n",
      "\n",
      "avg / total       0.67      0.67      0.67      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.879572\n",
      "Test Accuracy LOGISTIC: 0.718548\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.731495\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.72      0.73      1803\n",
      "          -       0.72      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.724458\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.70      0.72      1803\n",
      "          -       0.71      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.72      0.72      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.720799\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.70      0.72      1803\n",
      "          -       0.70      0.75      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression + Lemmatization sin remoción Stopwords.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def do_LOGIT(x,y,xt,yt):\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"Usando C= %f\"%C\n",
    "        model = LogisticRegression(penalty='l2',C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"LOGISTIC\")\n",
    "\n",
    "    \n",
    "texts_train = [word_extractor2(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text, False) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.782217\n",
      "Test Accuracy LOGISTIC: 0.690684\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.68      0.73      0.70      1803\n",
      "          -       0.70      0.65      0.68      1751\n",
      "\n",
      "avg / total       0.69      0.69      0.69      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.880135\n",
      "Test Accuracy LOGISTIC: 0.731213\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.75      0.74      1803\n",
      "          -       0.73      0.71      0.72      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 0.999719\n",
      "Test Accuracy LOGISTIC: 0.725303\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.73      1803\n",
      "          -       0.72      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.719111\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.71      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.711511\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.70      0.71      1803\n",
      "          -       0.70      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression + Stemming + remoción Stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def do_LOGIT(x,y,xt,yt):\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"Usando C= %f\"%C\n",
    "        model = LogisticRegression(penalty='l2',C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"LOGISTIC\")\n",
    "\n",
    "    \n",
    "texts_train = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.741418\n",
      "Test Accuracy LOGISTIC: 0.678019\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.68      0.69      0.68      1803\n",
      "          -       0.68      0.67      0.67      1751\n",
      "\n",
      "avg / total       0.68      0.68      0.68      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.874226\n",
      "Test Accuracy LOGISTIC: 0.732620\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.74      0.74      1803\n",
      "          -       0.73      0.72      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.735998\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.728680\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.72      0.73      1803\n",
      "          -       0.72      0.74      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.724740\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.71      0.72      1803\n",
      "          -       0.71      0.74      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.72      0.72      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression + Stemming sin remoción Stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def do_LOGIT(x,y,xt,yt):\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"Usando C= %f\"%C\n",
    "        model = LogisticRegression(penalty='l2',C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"LOGISTIC\")\n",
    "\n",
    "    \n",
    "texts_train = [word_extractor(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor(text, False) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo i)\n",
    "Se realizarán experimentos entrenando una máquina de vectores de soporte.\n",
    "A continuación se detallarán los experimentos realizados y se mostrarán los **mejores** resultados obtenidos para cada experimento según el parámetro de regularización.\n",
    "<center>\n",
    "<li>Support Vector Machine + lemmatization + remoción Stopwords + Parámetro de regularización = 0.1:\n",
    "<center>\n",
    "Train Set Precision: 98,95%<br>\n",
    "Test Set Precision: 72,36%\n",
    "</center>\n",
    "</li><br>\n",
    "\n",
    "<li>Support Vector Machine + lemmatization sin remoción Stopwords + Parámetro de regularización = 0.1:\n",
    "<center>\n",
    "Train Set Precision: 98,79%<br>\n",
    "Test Set Precision: 73,82%\n",
    "</center>\n",
    "</li><br>\n",
    "\n",
    "\n",
    "<li>Support Vector Machine + Stemming + remoción Stopwords + Parámetro de regularización = 0.1\n",
    "<center>\n",
    "Train Set Precision: 98,19%<br>\n",
    "Test Set Precision: 73,12%\n",
    "</center>\n",
    "</li><br>\n",
    "\n",
    "\n",
    "<li>Support Vector Machine + Stemming sin remoción Stopwords + Parámetro de regularización = 0.1:\n",
    "<center>\n",
    "Train Set Precision: 98,33%<br>\n",
    "Test Set Precision: 74,05%\n",
    "</center>\n",
    "</li>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.884637\n",
      "Test Accuracy SVM: 0.715170\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.989589\n",
      "Test Accuracy SVM: 0.723614\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.73      1803\n",
      "          -       0.72      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.702786\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.698565\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.697439\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.70      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM + Lemmatization + remoción stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "def do_SVM(x,y,xt,yt):\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"El valor de C que se esta probando: %f\"%C\n",
    "        model = LinearSVC(C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "        \n",
    "\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "        \n",
    "\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.873382\n",
      "Test Accuracy SVM: 0.719111\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.987901\n",
      "Test Accuracy SVM: 0.738249\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.713763\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.714889\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.71      0.71      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.714889\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM + Lemmatization sin remoción stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "def do_SVM(x,y,xt,yt):\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"El valor de C que se esta probando: %f\"%C\n",
    "        model = LinearSVC(C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "        \n",
    "\n",
    "texts_train = [word_extractor2(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text, False) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "        \n",
    "\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.873382\n",
      "Test Accuracy SVM: 0.729243\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.75      0.74      1803\n",
      "          -       0.73      0.71      0.72      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.981992\n",
      "Test Accuracy SVM: 0.731213\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.73      0.73      1803\n",
      "          -       0.73      0.73      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.701942\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.72      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.700535\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.700535\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM + Stemming + remoción stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "def do_SVM(x,y,xt,yt):\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"El valor de C que se esta probando: %f\"%C\n",
    "        model = LinearSVC(C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "        \n",
    "\n",
    "texts_train = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "        \n",
    "\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.869162\n",
      "Test Accuracy SVM: 0.731213\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.74      0.74      1803\n",
      "          -       0.73      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.983399\n",
      "Test Accuracy SVM: 0.740501\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.74      0.74      1803\n",
      "          -       0.73      0.74      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.717422\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.70      0.72      1803\n",
      "          -       0.70      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.715452\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.70      0.71      1803\n",
      "          -       0.70      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.713763\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.70      0.71      1803\n",
      "          -       0.70      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM + Stemming sin remoción stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "def do_SVM(x,y,xt,yt):\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"El valor de C que se esta probando: %f\"%C\n",
    "        model = LinearSVC(C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "        \n",
    "\n",
    "texts_train = [word_extractor(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor(text, False) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "        \n",
    "\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo j)\n",
    "Para realizar el gráfico solicitado, se realiza con los mejores resultados obtenidos de cada set de experimentos. Esto para que el gráfico sea legible y simple.<br>\n",
    "Se gráfica los experimentos realizados con Stemming y sin remoción de stopwords, esto porque coincidió que los mejores resultados en todos los modelos se obtuvieron con estos parámetros.<br>\n",
    "Al observar el gráfico se observa que el mejor resultado con los datos de pruebas se consigue utilizando Naive Bayes con stemming sin remoción de stopwords, que alcanza una accuracy de 76.21%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEPCAYAAABV6CMBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOEREJBIFh4iIRPL/AQACcy2YMlf8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcb50b61e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#ax.invert_xaxis()\n",
    "axlab = [\"NB\", \"MultNB\", \"LR\", \"SVM\"]\n",
    "ax_x = range(len(ax_y_test))\n",
    "ax_y_test = [76.21, 75.99, 73.59, 74.05]\n",
    "ax_y_train = [93.80, 94.06, 100., 98.33]\n",
    "\n",
    "\n",
    "ax.plot(ax_x, ax_y_train, 'bo', label=\"Train Data.\")\n",
    "ax.plot(ax_x, ax_y_train)\n",
    "plt.xticks(ax_x, axlab)\n",
    "ax.plot(ax_x, ax_y_test, 'go', label=\"Test Data.\")\n",
    "ax.plot(ax_x, ax_y_test)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Modelos\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
