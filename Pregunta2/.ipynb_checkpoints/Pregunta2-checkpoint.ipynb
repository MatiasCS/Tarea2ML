{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 2\n",
    "## Desarrollo a)\n",
    "Las clases son 2: +1 y -1, que indican si un comentario es positivo o negativo.\n",
    "A continuación se muestra la cantidad de ejemplos que pertenece a cada clase en cada conjunto.\n",
    "<table>\n",
    "<tr><td></td><td>Clase +1</td><td>Clase -1</td>\n",
    "</tr>\n",
    "<tr> <td>Train Set</td><td>1784</td><td>1770</td>\n",
    "</tr>\n",
    "<tr> <td>Test Set</td><td>1803</td><td>1751</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3554, 2)\n",
      "(3554, 2)\n",
      "   Sentiment                                               Text\n",
      "0         -1  everything's serious , poetic , earnest and --...\n",
      "1         -1  narratively , trouble every day is a plodding ...\n",
      "2          1  a truly wonderful tale combined with stunning ...\n",
      "3          1  jason patric and ray liotta make for one splen...\n",
      "4         -1  haneke keeps us at arm's length . guided more ...\n",
      "5         -1  richard pryor mined his personal horrors and c...\n",
      "6         -1  puts on airs of a hal hartley wannabe film -- ...\n",
      "7         -1  the characters are interesting and the relatio...\n",
      "8         -1  this long and relentlessly saccharine film is ...\n",
      "9         -1  the movie's progression into rambling incohere...\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "train_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.train\"\n",
    "test_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.dev\"\n",
    "train_data_f = urllib.urlretrieve(train_data_url, \"train_data.csv\")\n",
    "test_data_f = urllib.urlretrieve(test_data_url, \"test_data.csv\")\n",
    "ftr = open(\"train_data.csv\", \"r\")\n",
    "fts = open(\"test_data.csv\", \"r\")\n",
    "rows = [line.split(\" \",1) for line in ftr.readlines()]\n",
    "train_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "train_df['Sentiment'] = pd.to_numeric(train_df['Sentiment'])\n",
    "rows = [line.split(\" \",1) for line in fts.readlines()]\n",
    "test_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "test_df['Sentiment'] = pd.to_numeric(test_df['Sentiment'])\n",
    "print train_df.shape\n",
    "print test_df.shape\n",
    "print train_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784 1770 3554\n",
      "1803 1751 3554\n"
     ]
    }
   ],
   "source": [
    "clase_pos = train_df.Sentiment.value_counts()[-1]\n",
    "clase_neg = train_df.Sentiment.value_counts()[1]\n",
    "print clase_pos, clase_neg, clase_pos + clase_neg\n",
    "\n",
    "clase_pos = test_df.Sentiment.value_counts()[-1]\n",
    "clase_neg = test_df.Sentiment.value_counts()[1]\n",
    "print clase_pos, clase_neg, clase_pos + clase_neg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo b)\n",
    "Se utilizará el stemming de porter.\n",
    "Al realizar stemming se observa que las palabras obtenidas están cortadas a lo que se espera sea su raíz. Por ejemplo, se observa que movie se transforma en movi luego del stemming, cuando movi no tiene ningún significado.\n",
    "Por otra parte running se transforma en run, esta transformación si es coherente. Pero como se ha visto no funcionan siempre los algoritmos de stemming.\n",
    "\n",
    "Al no realizar stemming las palabras quedan como aparecen, a excepción de las stopwords que son removidas por su poco aporte de significado en las frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love eat cake\n",
      " runner eat cake\n",
      " run eat cake\n",
      " love eat cake\n",
      " love eat cake\n",
      " love eat cake\n",
      " n't love eat cake\n",
      " holywood movi best\n",
      " resembl\n",
      " cat run ran cactu cactus cacti commun commun\n",
      " jump\n",
      " awaken\n",
      " bestrew\n"
     ]
    }
   ],
   "source": [
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "def word_extractor(text, Filter=True):\n",
    "    stemmer = PorterStemmer()\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ stemmer.stem(word.lower()) for word in word_tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "    \n",
    "    for word in wordtokens:\n",
    "        if Filter == True:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        else:\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "\n",
    "print word_extractor(\"I love to eat cake\")\n",
    "print word_extractor(\"I am a runner and eat cake\")\n",
    "print word_extractor(\"I am running and eat cake\")\n",
    "print word_extractor(\"I love eating cake\")\n",
    "print word_extractor(\"I loved eating the cake\")\n",
    "print word_extractor(\"I do not love eating cake\")\n",
    "print word_extractor(\"I don't love eating cake\")\n",
    "print word_extractor(\"holywood movies are the best\")\n",
    "print word_extractor(\"resembling\")\n",
    "print word_extractor(\"cats running ran cactus cactuses cacti community communities\")\n",
    "print word_extractor(\"jumping\")\n",
    "print word_extractor(\"awakened\")\n",
    "print word_extractor(\"bestrewed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo c)\n",
    "Se utiliza el lematizador WordNet. A diferencia del stemming la lematización utiliza una base de datos léxica, por lo que sus resultados son mejores, dado que analiza morfológicamente las palabras.\n",
    "\n",
    "Los resultados muestran que stemming realiza más transformaciones que la lematización, sin embargo stemming tiende a dejar formas sintácticas que no existen. Por ejemplo transforma resembling en resembl. Por otra parte, la lematización fue capaz de detectar la raíz de community y comminities como community, siendo que stemming cortó ambas palabras a \"commun\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love eat cake\n",
      " runner eat cake\n",
      " running eat cake\n",
      " love eating cake\n",
      " loved eating cake\n",
      " love eating cake\n",
      " n't love eating cake\n",
      " holywood movie best\n",
      " running sun\n",
      " love eat cake\n",
      " cat running ran cactus cactus cactus community community\n",
      " jumping\n",
      " resembling\n",
      " awakened\n",
      " bestrewed\n"
     ]
    }
   ],
   "source": [
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "\n",
    "def word_extractor2(text, Filter=True):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ wordlemmatizer.lemmatize(word.lower()) for word in word_tokenize(text.decode('utf-8','ignore')) ]\n",
    "    for word in wordtokens:\n",
    "        if Filter == True:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        else:\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "\n",
    "print word_extractor2(\"I love to eat cake\")\n",
    "print word_extractor2(\"I am a runner and eat cake\")\n",
    "print word_extractor2(\"I am running and eat cake\")\n",
    "print word_extractor2(\"I love eating cake\")\n",
    "print word_extractor2(\"I loved eating the cake\")\n",
    "print word_extractor2(\"I do not love eating cake\")\n",
    "print word_extractor2(\"I don't love eating cake\")\n",
    "print word_extractor2(\"holywood movies are the best\")\n",
    "print word_extractor2(\"I am running to the sun\")\n",
    "print word_extractor2(\"I love to eat cake\")\n",
    "print word_extractor2(\"cats running ran cactus cactuses cacti community communities\")\n",
    "print word_extractor2(\"jumping\")\n",
    "print word_extractor2(\"resembling\")\n",
    "print word_extractor2(\"awakened\")\n",
    "print word_extractor2(\"bestrewed\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo d)\n",
    "Son 9663 palabras en total se listarán el top 10 palabras según frecuencia.\n",
    "Las palabras para el conjunto de entrenamiento y validación son:\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-s6z2{text-align:center}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-hgcj{font-weight:bold;text-align:center}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-hgcj\">Frecuencia Train Set</th>\n",
    "    <th class=\"tg-hgcj\">Término Train Set</th>\n",
    "    <th class=\"tg-hgcj\">Frecuencia Test Set</th>\n",
    "    <th class=\"tg-hgcj\">Término Test Set</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">566</td>\n",
    "    <td class=\"tg-s6z2\">film</td>\n",
    "    <td class=\"tg-s6z2\">558</td>\n",
    "    <td class=\"tg-s6z2\">film</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">481</td>\n",
    "    <td class=\"tg-baqh\">movie</td>\n",
    "    <td class=\"tg-baqh\">540</td>\n",
    "    <td class=\"tg-baqh\">movie</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">246</td>\n",
    "    <td class=\"tg-baqh\">one</td>\n",
    "    <td class=\"tg-baqh\">250</td>\n",
    "    <td class=\"tg-baqh\">one</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">245</td>\n",
    "    <td class=\"tg-baqh\">like</td>\n",
    "    <td class=\"tg-baqh\">238</td>\n",
    "    <td class=\"tg-baqh\">ha</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">224</td>\n",
    "    <td class=\"tg-baqh\">ha</td>\n",
    "    <td class=\"tg-baqh\">230</td>\n",
    "    <td class=\"tg-baqh\">like</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">183</td>\n",
    "    <td class=\"tg-baqh\">make</td>\n",
    "    <td class=\"tg-baqh\">197</td>\n",
    "    <td class=\"tg-baqh\">story</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">176</td>\n",
    "    <td class=\"tg-baqh\">story</td>\n",
    "    <td class=\"tg-baqh\">175</td>\n",
    "    <td class=\"tg-baqh\">character</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">163</td>\n",
    "    <td class=\"tg-baqh\">character</td>\n",
    "    <td class=\"tg-baqh\">165</td>\n",
    "    <td class=\"tg-baqh\">time</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">145</td>\n",
    "    <td class=\"tg-baqh\">comedy</td>\n",
    "    <td class=\"tg-baqh\">161</td>\n",
    "    <td class=\"tg-baqh\">make</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">143</td>\n",
    "    <td class=\"tg-baqh\">time</td>\n",
    "    <td class=\"tg-baqh\">134</td>\n",
    "    <td class=\"tg-baqh\">comedy</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape:  (3554, 9663)\n",
      "labels train:  [ 0.  0.  1.  1.  0.  0.  0.  0.  0.  0.]\n",
      "Train:  9663\n",
      "Test:  9663\n",
      "566 film\n",
      "481 movie\n",
      "246 one\n",
      "245 like\n",
      "224 ha\n",
      "183 make\n",
      "176 story\n",
      "163 character\n",
      "145 comedy\n",
      "143 time\n",
      "558 film\n",
      "540 movie\n",
      "250 one\n",
      "238 ha\n",
      "230 like\n",
      "197 story\n",
      "175 character\n",
      "165 time\n",
      "161 make\n",
      "134 comedy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "print \"features.shape: \", features_train.shape\n",
    "\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "print \"labels train: \", labels_train[:10]\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "dist = list(np.array(features_train.sum(axis=0)).reshape(-1,))\n",
    "dist_test = list(np.array(features_test.sum(axis=0)).reshape(-1,))\n",
    "\n",
    "array = zip(dist, vocab)\n",
    "array.sort()\n",
    "array.reverse()\n",
    "\n",
    "array2 = zip(dist_test, vocab)\n",
    "array2.sort()\n",
    "array2.reverse()\n",
    "\n",
    "print \"Train: \", len(array)\n",
    "print \"Test: \", len(array2)\n",
    "\n",
    "for count, tag in array[:10]:\n",
    "    print count, tag\n",
    "for count, tag in array2[:10]:\n",
    "    print count, tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo e)\n",
    "Las métricas que son entregadas por classification_report son: precision, recall, f1-score y support.\n",
    "<li>precision: Se calcula como tp/(tp+fp), lo que indica la habilidad del clasificador para no etiquetar como positivo una muestra que es negativa. (tp: true positive. fp: false positive).</li>\n",
    "<li>recall: Se calcula como tp/(tp+fn). Es la habilidad del clasificador para encontrar todas las muestras positivas. (fn:false negative).</li>\n",
    "<li>f1-score: Se calcula como 2*(precision*recall)/(precision+recall). Se interpreta como un promedio ponderado de la precision y recall. El mejor valor es 1 y corresponde cuando la contribución de precision y recall es igual. El peor caso es 0.</li>\n",
    "<li>support: Corresponde al número de ocurrencias de cada clase en los ejemplos correctamente clasificados como positivos.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def score_the_model(model,x,y,xt,yt,text):\n",
    "    acc_tr = model.score(x,y)\n",
    "    acc_test = model.score(xt[:-1],yt[:-1])\n",
    "    print \"Training Accuracy %s: %f\"%(text,acc_tr)\n",
    "    print \"Test Accuracy %s: %f\"%(text,acc_test)\n",
    "    print \"Detailed Analysis Testing Results ...\"\n",
    "    print(classification_report(yt, model.predict(xt), target_names=['+','-']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo f)\n",
    "\n",
    "Al entrenar un clasificador bayesiano ingenuo, se obtiene una precisión de 95,86% en los datos de entrenamiento y un 73,85% en los datos de prueba.\n",
    "Se utilizan los datos tal como fueron preprocesados en la pregunta 1.d), considerando que se realizó lematización y eliminación de stopwords antes de entrenar el modelo.\n",
    "\n",
    "Al entrenar sin realizar la eliminación de las stopwords, la predicción de entrenamiento decae a 95,52%, pero la predicción en los datos de prueba aumenta a 74,86%.\n",
    "\n",
    "\n",
    "Realizando las mismas pruebas anteriores, pero ahora utilizando stemming, se tiene lo siguiente:\n",
    "<li>Naive Bayes + Stemming + Remoción de Stopwords:\n",
    "<center><li>Precisión con los datos de entrenamiento: 94,28%</li><li>Precisión con los datos de pruebas: 74,78%</li></center>\n",
    "</li>\n",
    "<li>Relizando Naive Bayes + Stemming:\n",
    "<center><li>Precisión con los datos de entrenamiento: 93,80%</li><li>Precisión con los datos de pruebas: 76,21%</li></center>\n",
    "</li>\n",
    "\n",
    "Con respecto a las predicciones hechas por el clasificador se escogieron 4:\n",
    "\n",
    "[ 0.93359206  0.06640794] the problem is that the movie has no idea of it is serious or not.<br>\n",
    "Se puede apreciar que detecta con amplio margen que la sentencia pertenece a la clase 0. (93%)\n",
    "\n",
    "[ 0.10804209  0.89195791] visually striking and viscerally repellent .<br>\n",
    "Clasifica con un 89% que la frase es positiva. Esta podría entrar en duda ya que visceralmente repelente, significa que no es agradable de ver. Pero en el dataset se encuentra como positiva, por lo que es correcto.\n",
    "\n",
    "[ 0.76750338  0.23249662] the script is a disaster , with cloying messages and irksome characters .\n",
    "De alguna manera detecta con menor probabilidad que la sentencia pertenece a la clase 0 (76%). Aunque es correcto es curioso siendo que la sentencia es bastante explícita.\n",
    "\n",
    "\n",
    "[ 0.07564436  0.92435564] wickedly funny , visually engrossing , never boring , this movie challenges us to think about the ways we consume pop culture.\n",
    "La clasifica bien con una buena probabilidad. La sentencia es claramente positiva y le asigna una probabilidad de 92%. Coherente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.958638\n",
      "Test Accuracy BernoulliNB: 0.738531\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. naive bayes con lematización y extracción de stopwords.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import random\n",
    "\n",
    "def do_NAIVE_BAYES(x,y,xt,yt):\n",
    "    model = BernoulliNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"BernoulliNB\")\n",
    "    return model\n",
    "\n",
    "model=do_NAIVE_BAYES(features_train,labels_train,features_test,labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.955262\n",
      "Test Accuracy BernoulliNB: 0.748663\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.74      0.75      1803\n",
      "          -       0.74      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Modelo Naive Bayes con Lemmatization sin remoción de stopwords.\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts_train = [word_extractor2(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text, False) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "#labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "#labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "\n",
    "model = do_NAIVE_BAYES(features_train, labels_train, features_test, labels_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.942881\n",
      "Test Accuracy BernoulliNB: 0.747819\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.74      0.75      1803\n",
      "          -       0.74      0.75      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Naive Bayes Stemming y remoción de Stopwords.\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts_train = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "#labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "#labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "\n",
    "model = do_NAIVE_BAYES(features_train, labels_train, features_test, labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.938098\n",
      "Test Accuracy BernoulliNB: 0.762173\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.77      0.76      0.77      1803\n",
      "          -       0.76      0.76      0.76      1751\n",
      "\n",
      "avg / total       0.76      0.76      0.76      3554\n",
      "\n",
      "[ 0.93359206  0.06640794] the problem is that the movie has no idea of it is serious or not .\n",
      "\n",
      "[ 0.10804209  0.89195791] visually striking and viscerally repellent .\n",
      "\n",
      "[ 0.76750338  0.23249662] the script is a disaster , with cloying messages and irksome characters .\n",
      "\n",
      "[ 0.07564436  0.92435564] wickedly funny , visually engrossing , never boring , this movie challenges us to think about the ways we consume pop culture .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Naive Bayes Stemming sin remoción de stopwords.\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts_train = [word_extractor(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor(text, False) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "model = do_NAIVE_BAYES(features_train, labels_train, features_test, labels_test)\n",
    "\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = [6, 8, 12, 18]\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo g)\n",
    "A continuación se realiza el entrenamiento de un clasificador bayesiano multinomial variando el preprocesamiento de los datos.\n",
    "A continuación se detallarán los experimentos realizados:\n",
    "<li>Multinomial Naive Bayes + lemmatization + remoción Stopwords:\n",
    "<center>\n",
    "<li>Train Set Precision: 95,94%</li>\n",
    "<li>Test Set Precision: 74,07%</li>\n",
    "</center>\n",
    "</li>\n",
    "\n",
    "<li>Multinomial Naive Bayes + lemmatization sin remoción Stopwords:\n",
    "<center>\n",
    "<li>Train Set Precision: 95,55%</li>\n",
    "<li>Test Set Precision: 74,75%</li>\n",
    "</center>\n",
    "</li>\n",
    "\n",
    "<li>Multinomial Naive Bayes + Stemming + remoción Stopwords:\n",
    "<center>\n",
    "<li>Train Set Precision: 94,93%</li>\n",
    "<li>Test Set Precision: 74,97%</li>\n",
    "</center>\n",
    "</li>\n",
    "\n",
    "<li>Multinomial Naive Bayes + Stemming sin remoción Stopwords:\n",
    "<center>\n",
    "<li>Train Set Precision: 94,06%</li>\n",
    "<li>Test Set Precision: 75,99%</li>\n",
    "</center>\n",
    "</li>\n",
    "\n",
    "Se observa que los mejores resultados se presentan al combinar Multinomial Naive Bayes + Stemming sin remover las Stopwords.\n",
    "\n",
    "Con respecto a las predicciones del modelo se tienen las siguientes frases de ejemplo.\n",
    "\n",
    "[ 0.93275087  0.06724913] the problem is that the movie has no idea of it is serious or not.<br>\n",
    "Se comporta similar a Naive Bayes detecta con amplio margen que la sentencia pertenece a la clase 0. (93%)\n",
    "\n",
    "[ 0.13896173  0.86103827] visually striking and viscerally repellent .<br>\n",
    "A diferencia de Naive Bayes baja un poco la probabilidad de ser clase 1. Aunque de igual manera le asigna un 86% dejando clara la preferencia.\n",
    "\n",
    "[ 0.80203925  0.19796075] the script is a disaster , with cloying messages and irksome characters .<br>\n",
    "En esta sentencia se comporta mejor que Naive Bayes. Asigna mayor probabilidad a pertenecer a la clase 0.\n",
    "\n",
    "[ 0.06384922  0.93615078] wickedly funny , visually engrossing , never boring , this movie challenges us to think about the ways we consume pop culture .<br>\n",
    "En esta sentencia se comporta bien el clasificador le asigna una probabilidad de 93%, mejor que Naive Bayes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.959482\n",
      "Test Accuracy MULTINOMIAL: 0.740782\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Multinomial + lemmatization + remoción Stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import random\n",
    "\n",
    "def do_MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"MULTINOMIAL\")\n",
    "    return model\n",
    "\n",
    "\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.955543\n",
      "Test Accuracy MULTINOMIAL: 0.747537\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.75      0.75      1803\n",
      "          -       0.74      0.74      0.74      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Multinomial + lemmatization sin remoción Stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import random\n",
    "\n",
    "def do_MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"MULTINOMIAL\")\n",
    "    return model\n",
    "\n",
    "\n",
    "texts_train = [word_extractor2(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text, False) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.942319\n",
      "Test Accuracy MULTINOMIAL: 0.749789\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.75      0.75      1803\n",
      "          -       0.74      0.75      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Multinomial + Stemming + remoción Stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import random\n",
    "\n",
    "def do_MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"MULTINOMIAL\")\n",
    "    return model\n",
    "\n",
    "\n",
    "texts_train = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.940630\n",
      "Test Accuracy MULTINOMIAL: 0.759921\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.77      0.76      1803\n",
      "          -       0.76      0.75      0.76      1751\n",
      "\n",
      "avg / total       0.76      0.76      0.76      3554\n",
      "\n",
      "[ 0.93275087  0.06724913] the problem is that the movie has no idea of it is serious or not .\n",
      "\n",
      "[ 0.13896173  0.86103827] visually striking and viscerally repellent .\n",
      "\n",
      "[ 0.80203925  0.19796075] the script is a disaster , with cloying messages and irksome characters .\n",
      "\n",
      "[ 0.06384922  0.93615078] wickedly funny , visually engrossing , never boring , this movie challenges us to think about the ways we consume pop culture .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Multinomial + Stemming sin remoción Stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import random\n",
    "\n",
    "def do_MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"MULTINOMIAL\")\n",
    "    return model\n",
    "\n",
    "\n",
    "texts_train = [word_extractor(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor(text, False) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "\n",
    "model=do_MULTINOMIAL(features_train,labels_train,features_test,labels_test)\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = [6,8,12,18]\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo h)\n",
    "A continuación se realiza el entrenamiento de un clasificador utilizando regresión logística. Además se varía el preprocesamiento de los datos.\n",
    "\n",
    "A continuación se detallarán los experimentos realizados y se mostrarán los **mejores** resultados obtenidos para cada experimento según el parámetro de regularización.\n",
    "<center>\n",
    "<li>Logistic Regression + lemmatization + remoción Stopwords + Parámetro de regularización = 0.1:\n",
    "<center>\n",
    "Train Set Precision: 89,92%<br>\n",
    "Test Set Precision: 71,91%\n",
    "</center>\n",
    "</li><br>\n",
    "\n",
    "<li>Logistic Regression + lemmatization sin remoción Stopwords + Parámetro de regularización = 10.0:\n",
    "<center>\n",
    "Train Set Precision: 100%<br>\n",
    "Test Set Precision: 73,14%\n",
    "</center>\n",
    "</li><br>\n",
    "\n",
    "<li>Logistic Regression + Stemming + remoción Stopwords + Parámetro de regularización = 10.0:\n",
    "<center>\n",
    "Train Set Precision: 88,01%<br>\n",
    "Test Set Precision: 73,12%\n",
    "</center>\n",
    "</li><br>\n",
    "\n",
    "<li>Logistic Regression + Stemming sin remoción Stopwords + Parámetro de regularización = 0.1:\n",
    "<center>\n",
    "Train Set Precision: 100%<br>\n",
    "Test Set Precision: 73,59%\n",
    "</center>\n",
    "</li>\n",
    "</center>\n",
    "\n",
    "\n",
    "El **parámetro L2** es un penalizador que busca que el modelo no se sobreajuste. Encontrando un buen valor para este parámetro se evita esta situación.\n",
    "\n",
    "Con respecto a como se comporta al predecir se analizan las siguientes sentencias:\n",
    "[ 0.72918199  0.27081801] the problem is that the movie has no idea of it is serious or not .<br>\n",
    "Se encuentra bien clasificada, pero obtiene peor precisión que los modelos vistos hasta el momento.\n",
    "\n",
    "[ 0.38415591  0.61584409] visually striking and viscerally repellent .\n",
    "Bien clasificado, pero con la peor probabilidad hasta el momento.\n",
    "\n",
    "[ 0.62118524  0.37881476] the script is a disaster , with cloying messages and irksome characters .\n",
    "La sentencia es explícita al decir que es una mala calificación. Aún así el resultado es pobre.\n",
    "\n",
    "[ 0.49333753  0.50666247] wickedly funny , visually engrossing , never boring , this movie challenges us to think about the ways we consume pop culture .\n",
    "Aunque se encuentra clasificada como positiva, el modelo lo hace apenas. La sentencia es claramente positiva, aún así se encuentra al borde de clasificar mal.\n",
    "\n",
    "Con respecto a los modelos vistos hasta ahora, sus predicciones tienden a no ser tajantes. Las probabilidades asociadas a cada sentencia, aunque siendo correctas son menos certeras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.784468\n",
      "Test Accuracy LOGISTIC: 0.678863\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.67      0.73      0.70      1803\n",
      "          -       0.69      0.63      0.66      1751\n",
      "\n",
      "avg / total       0.68      0.68      0.68      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.892234\n",
      "Test Accuracy LOGISTIC: 0.719111\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.72      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.718548\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.714044\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.71      0.72      1803\n",
      "          -       0.71      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.712356\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.71      0.71      1803\n",
      "          -       0.70      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression + Lemmatization + remoción Stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def do_LOGIT(x,y,xt,yt):\n",
    "    models = []\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"Usando C= %f\"%C\n",
    "        model = LogisticRegression(penalty='l2',C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"LOGISTIC\")\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "    \n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "models = do_LOGIT(features_train,labels_train,features_test,labels_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.734102\n",
      "Test Accuracy LOGISTIC: 0.671827\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.68      0.68      0.68      1803\n",
      "          -       0.67      0.66      0.67      1751\n",
      "\n",
      "avg / total       0.67      0.67      0.67      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.879572\n",
      "Test Accuracy LOGISTIC: 0.718548\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.731495\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.72      0.73      1803\n",
      "          -       0.72      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.724458\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.70      0.72      1803\n",
      "          -       0.71      0.75      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.72      0.72      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.720799\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.70      0.72      1803\n",
      "          -       0.70      0.75      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression + Lemmatization sin remoción Stopwords.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def do_LOGIT(x,y,xt,yt):\n",
    "    models = []\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"Usando C= %f\"%C\n",
    "        model = LogisticRegression(penalty='l2',C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"LOGISTIC\")\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "    \n",
    "texts_train = [word_extractor2(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text, False) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "models = do_LOGIT(features_train,labels_train,features_test,labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.782217\n",
      "Test Accuracy LOGISTIC: 0.690684\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.68      0.73      0.70      1803\n",
      "          -       0.70      0.65      0.68      1751\n",
      "\n",
      "avg / total       0.69      0.69      0.69      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.880135\n",
      "Test Accuracy LOGISTIC: 0.731213\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.75      0.74      1803\n",
      "          -       0.73      0.71      0.72      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 0.999719\n",
      "Test Accuracy LOGISTIC: 0.725303\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.73      1803\n",
      "          -       0.72      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.719111\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.71      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.711511\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.70      0.71      1803\n",
      "          -       0.70      0.72      0.71      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression + Stemming + remoción Stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def do_LOGIT(x,y,xt,yt):\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"Usando C= %f\"%C\n",
    "        model = LogisticRegression(penalty='l2',C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"LOGISTIC\")\n",
    "\n",
    "    \n",
    "texts_train = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "do_LOGIT(features_train,labels_train,features_test,labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.741418\n",
      "Test Accuracy LOGISTIC: 0.678019\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.68      0.69      0.68      1803\n",
      "          -       0.68      0.67      0.67      1751\n",
      "\n",
      "avg / total       0.68      0.68      0.68      3554\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.874226\n",
      "Test Accuracy LOGISTIC: 0.732620\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.74      0.74      1803\n",
      "          -       0.73      0.72      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.735998\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.728680\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.72      0.73      1803\n",
      "          -       0.72      0.74      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 0.724740\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.71      0.72      1803\n",
      "          -       0.71      0.74      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.72      0.72      3554\n",
      "\n",
      "[ 0.72918199  0.27081801] the problem is that the movie has no idea of it is serious or not .\n",
      "\n",
      "[ 0.38415591  0.61584409] visually striking and viscerally repellent .\n",
      "\n",
      "[ 0.62118524  0.37881476] the script is a disaster , with cloying messages and irksome characters .\n",
      "\n",
      "[ 0.49333753  0.50666247] wickedly funny , visually engrossing , never boring , this movie challenges us to think about the ways we consume pop culture .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression + Stemming sin remoción Stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def do_LOGIT(x,y,xt,yt):\n",
    "    models = []\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"Usando C= %f\"%C\n",
    "        model = LogisticRegression(penalty='l2',C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"LOGISTIC\")\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "    \n",
    "texts_train = [word_extractor(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor(text, False) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "models = do_LOGIT(features_train,labels_train,features_test,labels_test)\n",
    "model = models[1]\n",
    "\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = [6,8,12,18]\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo i)\n",
    "Se realizarán experimentos entrenando una máquina de vectores de soporte.\n",
    "A continuación se detallarán los experimentos realizados y se mostrarán los **mejores** resultados obtenidos para cada experimento según el parámetro de regularización.\n",
    "<center>\n",
    "<li>Support Vector Machine + lemmatization + remoción Stopwords + Parámetro de regularización = 0.1:\n",
    "<center>\n",
    "Train Set Precision: 98,95%<br>\n",
    "Test Set Precision: 72,36%\n",
    "</center>\n",
    "</li><br>\n",
    "\n",
    "<li>Support Vector Machine + lemmatization sin remoción Stopwords + Parámetro de regularización = 0.1:\n",
    "<center>\n",
    "Train Set Precision: 98,79%<br>\n",
    "Test Set Precision: 73,82%\n",
    "</center>\n",
    "</li><br>\n",
    "\n",
    "\n",
    "<li>Support Vector Machine + Stemming + remoción Stopwords + Parámetro de regularización = 0.1\n",
    "<center>\n",
    "Train Set Precision: 98,19%<br>\n",
    "Test Set Precision: 73,12%\n",
    "</center>\n",
    "</li><br>\n",
    "\n",
    "\n",
    "<li>Support Vector Machine + Stemming sin remoción Stopwords + Parámetro de regularización = 0.1:\n",
    "<center>\n",
    "Train Set Precision: 98,33%<br>\n",
    "Test Set Precision: 74,05%\n",
    "</center>\n",
    "</li>\n",
    "</center>\n",
    "\n",
    "Las predicciones del modelo se analizan tomando como ejemplo las siguientes sentencias:\n",
    "\n",
    "[ 0.76278434  0.23721566] the problem is that the movie has no idea of it is serious or not .<br>\n",
    "Le asigna alta probabilidad a las clase 0. Detecta bien la sentencia.\n",
    "\n",
    "[ 0.32106571  0.67893429] visually striking and viscerally repellent.\n",
    "La probabilidad de las clase 1 es 67%. Es correcto y se puede esperar un bajo porcentaje debido a las palabras presentes en la sentencia \"repelente\".\n",
    "\n",
    "[ 0.76501132  0.23498868] the script is a disaster , with cloying messages and irksome characters .\n",
    "Las palabras \"disaster\" y \"irksome\" son claros indicadores de que la sentencia es negativa.\n",
    "\n",
    "[ 0.43973125  0.56026875] wickedly funny , visually engrossing , never boring , this movie challenges us to think about the ways we consume pop culture .\n",
    "Esta es la frase más controversial. Existen señales claras de que es una calificación positiva y aún así obtiene las probabilidades más bajas para la clase 1. Aunque siempre siendo correctamente clasificada.\n",
    "\n",
    "Cabe agregar que estas sentencias están todas correctamente clasificadas. No es el mejor modelo de los estudiados previamente, pero es aceptable entre los vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.884637\n",
      "Test Accuracy SVM: 0.715170\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.989589\n",
      "Test Accuracy SVM: 0.723614\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.73      1803\n",
      "          -       0.72      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.702786\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.698565\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.697439\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.70      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM + Lemmatization + remoción stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "def do_SVM(x,y,xt,yt):\n",
    "    models = []\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"El valor de C que se esta probando: %f\"%C\n",
    "        model = LinearSVC(C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "texts_train = [word_extractor2(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "        \n",
    "\n",
    "models = do_SVM(features_train,labels_train,features_test,labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.873382\n",
      "Test Accuracy SVM: 0.719111\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.72      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.987901\n",
      "Test Accuracy SVM: 0.738249\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.713763\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.714889\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.71      0.71      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.714889\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.69      0.71      1803\n",
      "          -       0.70      0.74      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.71      0.71      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM + Lemmatization sin remoción stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "def do_SVM(x,y,xt,yt):\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"El valor de C que se esta probando: %f\"%C\n",
    "        model = LinearSVC(C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "        \n",
    "\n",
    "texts_train = [word_extractor2(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor2(text, False) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "        \n",
    "\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.873382\n",
      "Test Accuracy SVM: 0.729243\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.75      0.74      1803\n",
      "          -       0.73      0.71      0.72      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.981992\n",
      "Test Accuracy SVM: 0.731213\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.73      0.73      1803\n",
      "          -       0.73      0.73      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.701942\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.72      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.700535\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.700535\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM + Stemming + remoción stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "def do_SVM(x,y,xt,yt):\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"El valor de C que se esta probando: %f\"%C\n",
    "        model = LinearSVC(C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "        \n",
    "\n",
    "texts_train = [word_extractor(text) for text in train_df.Text]\n",
    "texts_test = [word_extractor(text) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "        \n",
    "\n",
    "do_SVM(features_train,labels_train,features_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.840743\n",
      "Test Accuracy SVM: 0.727273\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.74      0.73      1803\n",
      "          -       0.73      0.71      0.72      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.963703\n",
      "Test Accuracy SVM: 0.746130\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.75      0.75      1803\n",
      "          -       0.74      0.74      0.74      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 0.997749\n",
      "Test Accuracy SVM: 0.730369\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.72      0.73      1803\n",
      "          -       0.72      0.74      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 0.996905\n",
      "Test Accuracy SVM: 0.729243\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.72      0.73      1803\n",
      "          -       0.72      0.74      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 0.996905\n",
      "Test Accuracy SVM: 0.728961\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.72      0.73      1803\n",
      "          -       0.72      0.74      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "[ 0.76278434  0.23721566] the problem is that the movie has no idea of it is serious or not .\n",
      "\n",
      "[ 0.32106571  0.67893429] visually striking and viscerally repellent .\n",
      "\n",
      "[ 0.76501132  0.23498868] the script is a disaster , with cloying messages and irksome characters .\n",
      "\n",
      "[ 0.43973125  0.56026875] wickedly funny , visually engrossing , never boring , this movie challenges us to think about the ways we consume pop culture .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM + Stemming sin remoción stopwords\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def do_SVM(x,y,xt,yt):\n",
    "    models = []\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"El valor de C que se esta probando: %f\"%C\n",
    "        svm = LinearSVC(C=C)\n",
    "        model = CalibratedClassifierCV(svm) \n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "#y_proba = clf.predict_proba(X_test)\n",
    "\n",
    "texts_train = [word_extractor(text, False) for text in train_df.Text]\n",
    "texts_test = [word_extractor(text, False) for text in test_df.Text]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "vectorizer.fit(np.asarray(texts_train))\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "        \n",
    "\n",
    "models = do_SVM(features_train,labels_train,features_test,labels_test)\n",
    "model = models[1]\n",
    "test_pred = model.predict_proba(features_test)\n",
    "\n",
    "spl = [6,8,12,18]\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo j)\n",
    "Para realizar el gráfico solicitado, se realiza con los mejores resultados obtenidos de cada set de experimentos. Esto para que el gráfico sea legible y simple.<br>\n",
    "Se gráfica los experimentos realizados con Stemming y sin remoción de stopwords, esto porque coincidió que los mejores resultados en todos los modelos se obtuvieron con estos parámetros.<br>\n",
    "Al observar el gráfico se observa que el mejor resultado con los datos de pruebas se consigue utilizando Naive Bayes con stemming sin remoción de stopwords, que alcanza una accuracy de 76.21%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEPCAYAAABV6CMBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOEREJBIFh4iIRPL/AQACcy2YMlf8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb919083310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#ax.invert_xaxis()\n",
    "axlab = [\"NB\", \"MultNB\", \"LR\", \"SVM\"]\n",
    "ax_x = range(len(axlab))\n",
    "ax_y_test = [76.21, 75.99, 73.59, 74.05]\n",
    "ax_y_train = [93.80, 94.06, 100., 98.33]\n",
    "\n",
    "\n",
    "ax.plot(ax_x, ax_y_train, 'bo', label=\"Train Data.\")\n",
    "ax.plot(ax_x, ax_y_train)\n",
    "plt.xticks(ax_x, axlab)\n",
    "ax.plot(ax_x, ax_y_test, 'go', label=\"Test Data.\")\n",
    "ax.plot(ax_x, ax_y_test)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Modelos\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
