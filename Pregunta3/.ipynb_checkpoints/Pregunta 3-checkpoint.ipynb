{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "user_skills = open('user_skill','r')\n",
    "\n",
    "col = []\n",
    "row = []\n",
    "data = []\n",
    "\n",
    "counter = 0\n",
    "for line in user_skills:\n",
    "    line = line.strip('\\n')\n",
    "    skills = map(int,line.split(':')[1].split(','))\n",
    "    data += ([1]*len(skills))\n",
    "    row +=([counter]*len(skills))\n",
    "    col += (skills)\n",
    "    counter +=1\n",
    "\n",
    "user_skills.close()\n",
    "col = np.asarray(col)\n",
    "row = np.asarray(row)\n",
    "data = np.asarray(data)\n",
    "Z = csr_matrix((data,(row, col)),shape= (counter+1,14544))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nrows = np.shape(Z)[0]\n",
    "Z=shuffle(Z, random_state = 0)\n",
    "train_size = int(0.7*nrows)\n",
    "Ztr = Z[range(train_size),:]\n",
    "Zts = Z[range(train_size, nrows),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "skills_count = np.asarray(Z.sum(axis=0))[0]\n",
    "skills_labels = []\n",
    "skills_id = open('skill_id','r')\n",
    "for line in skills_id:\n",
    "    skills_labels.append(unicode(line.split(' :')[0],'utf-8'))\n",
    "    \n",
    "dictionary = dict(zip(skills_labels, skills_count.T))\n",
    "x = []\n",
    "y = []\n",
    "for i in range(20):\n",
    "    skill = max(dictionary.iteritems(), key=operator.itemgetter(1))[0]\n",
    "    x.append(skill)\n",
    "    y.append(dictionary.get(skill))\n",
    "    del dictionary[skill]\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "width = 0.75 # the width of the bars \n",
    "ind = np.arange(len(y))  # the x locations for the groups\n",
    "ax.barh(ind, y, width, color=\"blue\")\n",
    "ax.set_yticks(ind+width/2)\n",
    "ax.set_yticklabels(x, minor=False)\n",
    "plt.title('Top 20 Skills Linkedin')\n",
    "plt.xlabel('Users with the Skill')\n",
    "plt.ylabel('Skill')      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def score_the_model(model,x,y,xt,yt,text):\n",
    "    acc_tr = model.score(x,y)\n",
    "    acc_test = model.score(xt[:-1],yt[:-1])\n",
    "    print \"Training Accuracy %s: %f\"%(text,acc_tr)\n",
    "    print \"Test Accuracy %s: %f\"%(text,acc_test)\n",
    "    print \"Detailed Analysis Testing Results ...\"\n",
    "    print(classification_report(yt, model.predict(xt), target_names=['+','-']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "def do_LOGIT(x,y,xt,yt):\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"Usando C= %f\"%C\n",
    "        model = LogisticRegression(penalty='l2',C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"LOGISTIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.840666\n",
      "Test Accuracy LOGISTIC: 0.838614\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.84      0.91      0.87      1443\n",
      "          -       0.84      0.73      0.78       925\n",
      "\n",
      "avg / total       0.84      0.84      0.84      2368\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.877422\n",
      "Test Accuracy LOGISTIC: 0.831432\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.84      0.89      0.87      1443\n",
      "          -       0.81      0.74      0.77       925\n",
      "\n",
      "avg / total       0.83      0.83      0.83      2368\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 0.978454\n",
      "Test Accuracy LOGISTIC: 0.785382\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.82      0.83      0.83      1443\n",
      "          -       0.73      0.71      0.72       925\n",
      "\n",
      "avg / total       0.78      0.79      0.78      2368\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 0.986964\n",
      "Test Accuracy LOGISTIC: 0.767216\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.81      0.81      0.81      1443\n",
      "          -       0.70      0.70      0.70       925\n",
      "\n",
      "avg / total       0.77      0.77      0.77      2368\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 0.990042\n",
      "Test Accuracy LOGISTIC: 0.739332\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.79      0.78      0.79      1443\n",
      "          -       0.67      0.67      0.67       925\n",
      "\n",
      "avg / total       0.74      0.74      0.74      2368\n",
      "\n",
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.926127\n",
      "Test Accuracy LOGISTIC: 0.918040\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.92      1.00      0.96      2165\n",
      "          -       0.91      0.05      0.09       203\n",
      "\n",
      "avg / total       0.92      0.92      0.88      2368\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.943509\n",
      "Test Accuracy LOGISTIC: 0.921842\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.93      0.99      0.96      2165\n",
      "          -       0.66      0.18      0.29       203\n",
      "\n",
      "avg / total       0.91      0.92      0.90      2368\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 0.992214\n",
      "Test Accuracy LOGISTIC: 0.907055\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.93      0.97      0.95      2165\n",
      "          -       0.43      0.27      0.33       203\n",
      "\n",
      "avg / total       0.89      0.91      0.90      2368\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 0.997465\n",
      "Test Accuracy LOGISTIC: 0.886777\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.93      0.94      0.94      2165\n",
      "          -       0.32      0.29      0.30       203\n",
      "\n",
      "avg / total       0.88      0.89      0.88      2368\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 0.999638\n",
      "Test Accuracy LOGISTIC: 0.870722\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.94      0.92      0.93      2165\n",
      "          -       0.28      0.32      0.30       203\n",
      "\n",
      "avg / total       0.88      0.87      0.87      2368\n",
      "\n",
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.999819\n",
      "Test Accuracy LOGISTIC: 1.000000\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      1.00      1.00      2368\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2368\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.999819\n",
      "Test Accuracy LOGISTIC: 1.000000\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      1.00      1.00      2368\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2368\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 1.000000\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      1.00      1.00      2368\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2368\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 1.000000\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      1.00      1.00      2368\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2368\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 1.000000\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      1.00      1.00      2368\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_skills = [29, 255, 8185]\n",
    "for skill in selected_skills:\n",
    "    ytr = Ztr[:,skill]\n",
    "    Xtr = csr_matrix(np.delete(Ztr.toarray(),skill,1))\n",
    "    yts = Zts[:,skill]\n",
    "    Xts = csr_matrix(np.delete(Zts.toarray(),skill,1))\n",
    "    model=do_LOGIT(Xtr, ytr.toarray()[:,0], Xts, yts.toarray()[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
