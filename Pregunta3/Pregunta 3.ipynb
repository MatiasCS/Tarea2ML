{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7891\n",
      "(7891, 14544)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "user_skills = open('user_skill','r')\n",
    "\n",
    "col = []\n",
    "row = []\n",
    "data = []\n",
    "\n",
    "counter = 0\n",
    "for line in user_skills:\n",
    "    line = line.strip('\\n')\n",
    "    skills = map(int,line.split(':')[1].split(','))\n",
    "    data += ([1]*len(skills))\n",
    "    row +=([counter]*len(skills))\n",
    "    col += (skills)\n",
    "    counter += 1\n",
    "\n",
    "user_skills.close()\n",
    "col = np.asarray(col)\n",
    "row = np.asarray(row)\n",
    "data = np.asarray(data)\n",
    "Z = csr_matrix((data,(row, col)), shape = (counter+1,14544))\n",
    "print len(Z.toarray())\n",
    "print Z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nrows = np.shape(Z)[0]\n",
    "Z=shuffle(Z, random_state = 0)\n",
    "train_size = int(0.7*nrows)\n",
    "Ztr = Z[range(train_size),:]\n",
    "Zts = Z[range(train_size, nrows),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAEZCAYAAACKO2zVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmSQUY69yRJkiQZZPw/azm9KIkBhPoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f11f710fe50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import operator\n",
    "skills_count = np.asarray(Z.sum(axis=0))[0]\n",
    "skills_labels = []\n",
    "skills_id = open('skill_id','r')\n",
    "for line in skills_id:\n",
    "    skills_labels.append(unicode(line.split(' :')[0],'utf-8'))\n",
    "    \n",
    "dictionary = dict(zip(skills_labels, skills_count.T))\n",
    "x = []\n",
    "y = []\n",
    "for i in range(20):\n",
    "    skill = max(dictionary.iteritems(), key=operator.itemgetter(1))[0]\n",
    "    x.append(skill)\n",
    "    y.append(dictionary.get(skill))\n",
    "    del dictionary[skill]\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "width = 0.75 # the width of the bars \n",
    "ind = np.arange(len(y))  # the x locations for the groups\n",
    "ax.barh(ind, y, width, color=\"blue\")\n",
    "ax.set_yticks(ind+width/2)\n",
    "ax.set_yticklabels(x, minor=False)\n",
    "plt.title('Top 20 Skills Linkedin')\n",
    "plt.xlabel('Users with the Skill')\n",
    "plt.ylabel('Skill')      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo d)\n",
    "Se incluye dentro del desarrollo de la pregunta f). No se hace aquí debido a que es necesario modificar los vectores de entrenamiento y test según la skill para la que se esté entrenando el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.978040540541\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "selected_skills = [639]\n",
    "for skill in selected_skills:\n",
    "    ytr = Ztr[:,skill]\n",
    "    Xtr = csr_matrix(np.delete(Ztr.toarray(),skill,1))\n",
    "    yts = Zts[:,skill]\n",
    "    Xts = csr_matrix(np.delete(Zts.toarray(),skill,1))\n",
    "    \n",
    "    #Logistic Regression model\n",
    "    logit_model = linear_model.LogisticRegression(C=1e5)\n",
    "    ytr = np.ravel(ytr.toarray())\n",
    "    yts = np.ravel(yts.toarray())\n",
    "    logit_model.fit(Xtr, ytr)\n",
    "    \n",
    "    print logit_model.score(Xtr, ytr)\n",
    "    print logit_model.score(Xts, yts)\n",
    "    \n",
    "#TODO: implementar cross validation para escoger parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo e)\n",
    "Se incluye dentro del desarrollo de la pregunta f). La skill escogida para esta pregunta es id 29. Se hace de esta manera para facilitar el análisis de la pregunta f).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Desarrollo f) Modelos\n",
    "\n",
    "Dado que los objetivos son entrenar varios modelos con distintas skill como target, se escogieron 3 distintas que poseen distintos porcentajes de presencia dentro del dataset.\n",
    "\n",
    "Se escogieron las siguientes 3 skill:\n",
    "<li>id 29: Microsoft Office con 3081 perfiles. Aproximadamente 39.04%. Utilizada en pregunta e)</li>\n",
    "<li>id 255: SAP con 639 perfiles. Aproximadamente 8.09%</li>\n",
    "<li>id 8185: Business Inteligence con 1594 perfiles. Aproximadamente 20.20%</li>\n",
    "\n",
    "Como se ve la presencia de estas skill varía de los 8% (SAP), hasta 39% (Microsoft Office). Con esto se busca observar el comportamiento de las técnicas de clasificación según el soporte dentro del dataset.\n",
    "\n",
    "**Logistic Regression:**<br>\n",
    "Para el skill Microsoft Office se observa que la mejor precision en el dataset de entrenamiento se da cuando el valor del parámetro C es igual a 0.01. Logrando una  precisión de 0.83\n",
    "\n",
    "Para el skill SAP se observa que la mejor precision en el dataset de entrenamiento se da cuando el valor del parámetro C es igual a 0.1. Logrando una  precisión de 0.92\n",
    "\n",
    "Para el skill Business Inteligence se observa que la mejor precision en el dataset de entrenamiento se da cuando el valor del parámetro C es igual a 0.01. Logrando una  precisión de 1\n",
    "\n",
    "**A continuación se muestran resumidos los resultados obtenidos.**\n",
    "\n",
    "\n",
    "**Skill 29 Microsoft Office:**\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-s6z2{text-align:center}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-hgcj{font-weight:bold;text-align:center}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-hgcj\">Skill 29</th>\n",
    "    <th class=\"tg-hgcj\">Train Accuracy</th>\n",
    "    <th class=\"tg-hgcj\">Test Accuracy</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">NB</td>\n",
    "    <td class=\"tg-s6z2\">84.77%</td>\n",
    "    <td class=\"tg-s6z2\">79.97%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">MNB</td>\n",
    "    <td class=\"tg-baqh\">84.41%</td>\n",
    "    <td class=\"tg-baqh\">78.91%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">SVM 0.01</td>\n",
    "    <td class=\"tg-baqh\">87.92%</td>\n",
    "    <td class=\"tg-baqh\">83.10%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">LR 0.01</td>\n",
    "    <td class=\"tg-baqh\">84.06%</td>\n",
    "    <td class=\"tg-baqh\">83.86%</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Para la skill 29 Microsoft Office, los mejores resultados se obtuvieron utilizando LR con un parámetro de regularización de 0.01. Como se muestra en la tabla, además se entrenaron modelos de Naive Bayes, Multinomial Naive Bayes y SVM. Dentro de los parámetros de regularización utilizados para SVM se encuentran 0.01, 0.1, 10, 100 y 1000, pero en la tabla solo se muestra aquel con el que se obtuvo la mejor precisión (0.01).\n",
    "\n",
    "**Skill 255 SAP:**\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-s6z2{text-align:center}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-hgcj{font-weight:bold;text-align:center}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-hgcj\">Skill 255</th>\n",
    "    <th class=\"tg-hgcj\">Train Accuracy</th>\n",
    "    <th class=\"tg-hgcj\">Test Accuracy</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">NB</td>\n",
    "    <td class=\"tg-s6z2\">92.77%</td>\n",
    "    <td class=\"tg-s6z2\">89.52%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">MNB</td>\n",
    "    <td class=\"tg-baqh\">93.02%</td>\n",
    "    <td class=\"tg-baqh\">86.60%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">SVM 0.01</td>\n",
    "    <td class=\"tg-baqh\">94.31%</td>\n",
    "    <td class=\"tg-baqh\">92.35%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">LR 0.1</td>\n",
    "    <td class=\"tg-baqh\">94.35%</td>\n",
    "    <td class=\"tg-baqh\">92.18%</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "La siguiente skill escogida es 255 SAP. Para esta skill el mejor resultado se obtuvo con Support vector machine. La precisión de pruebas alcanzada fue de 92.35%, con parámetro de regularización igual a 0.01. Se observan en la tabla los otros resultados obtenidos para los distintos modelos entrenados.\n",
    "\n",
    "**Skill 8185 Business Intelligence:**\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-s6z2{text-align:center}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-hgcj{font-weight:bold;text-align:center}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-hgcj\">Skill 8185</th>\n",
    "    <th class=\"tg-hgcj\">Train Accuracy</th>\n",
    "    <th class=\"tg-hgcj\">Test Accuracy</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">NB</td>\n",
    "    <td class=\"tg-s6z2\">99.98%</td>\n",
    "    <td class=\"tg-s6z2\">100%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">MNB</td>\n",
    "    <td class=\"tg-baqh\">99.49%</td>\n",
    "    <td class=\"tg-baqh\">98.73%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">SVM &gt;0.1</td>\n",
    "    <td class=\"tg-baqh\">100%</td>\n",
    "    <td class=\"tg-baqh\">100%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">LR 0.01</td>\n",
    "    <td class=\"tg-baqh\">99.98%</td>\n",
    "    <td class=\"tg-baqh\">100%</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Por último para la skill 8185 BI, el mejor resultado se obtuvo con Naive Bayes y Logistic Regression. Con ambos se obtuvo un 100% de precisión con los datos de pruebas y un 99.98% de precisión con los datos de entrenamiento. Si bien esto parece no estar correcto, hay muchos factores por los cuales se pudo haber obtenido este resultado. Por ejemplo, la cantidad de datos con los que se prueba el modelo. La cantidad de ejemplos de cada clase presente en los dataset de train y test, entre otros factores.\n",
    "\n",
    "\n",
    "Cabe agregar que con los resultados obtenidos, no parece haber una relación entre la cantidad de muestras de cada clase y la calidad del modelo generado.\n",
    "Según las tablas anteriormente descritas los mejores resultados se obtienen con la Skill Business Intelligence que está presente en un 20% de los perfiles. Luego le siguen los modelos de la skill SAP que está presente en un 8% de los perfiles. Y la skill Microsoft Office, que se encuentra presente en un 39.09% de los perfiles obtiene los peores resultados. (Sobre el 79%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función para obtener los resultados de cada modelo.\n",
    "from sklearn.metrics import classification_report\n",
    "def score_the_model(model,x,y,xt,yt,text):\n",
    "    acc_tr = model.score(x,y)\n",
    "    acc_test = model.score(xt[:-1],yt[:-1])\n",
    "    print \"Training Accuracy %s: %f\"%(text,acc_tr)\n",
    "    print \"Test Accuracy %s: %f\"%(text,acc_test)\n",
    "    print \"Detailed Analysis Testing Results ...\"\n",
    "    print(classification_report(yt, model.predict(xt), target_names=['+','-']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "def do_LOGIT(x,y,xt,yt):\n",
    "    start_t = time.time()\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"Usando C= %f\"%C\n",
    "        model = LogisticRegression(penalty='l2',C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"LOGISTIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo para el skill: Microsoft Office\n",
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.840666\n",
      "Test Accuracy LOGISTIC: 0.838614\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.84      0.91      0.87      1443\n",
      "          -       0.84      0.73      0.78       925\n",
      "\n",
      "avg / total       0.84      0.84      0.84      2368\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.877422\n",
      "Test Accuracy LOGISTIC: 0.831432\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.84      0.89      0.87      1443\n",
      "          -       0.81      0.74      0.77       925\n",
      "\n",
      "avg / total       0.83      0.83      0.83      2368\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 0.978454\n",
      "Test Accuracy LOGISTIC: 0.785382\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.82      0.83      0.83      1443\n",
      "          -       0.73      0.71      0.72       925\n",
      "\n",
      "avg / total       0.78      0.79      0.78      2368\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 0.986964\n",
      "Test Accuracy LOGISTIC: 0.767216\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.81      0.81      0.81      1443\n",
      "          -       0.70      0.70      0.70       925\n",
      "\n",
      "avg / total       0.77      0.77      0.77      2368\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 0.990042\n",
      "Test Accuracy LOGISTIC: 0.738910\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.79      0.78      0.79      1443\n",
      "          -       0.66      0.67      0.67       925\n",
      "\n",
      "avg / total       0.74      0.74      0.74      2368\n",
      "\n",
      "Modelo para el skill: SAP\n",
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.926127\n",
      "Test Accuracy LOGISTIC: 0.918040\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.92      1.00      0.96      2165\n",
      "          -       0.91      0.05      0.09       203\n",
      "\n",
      "avg / total       0.92      0.92      0.88      2368\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.943509\n",
      "Test Accuracy LOGISTIC: 0.921842\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.93      0.99      0.96      2165\n",
      "          -       0.66      0.18      0.29       203\n",
      "\n",
      "avg / total       0.91      0.92      0.90      2368\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 0.992214\n",
      "Test Accuracy LOGISTIC: 0.907055\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.93      0.97      0.95      2165\n",
      "          -       0.43      0.27      0.33       203\n",
      "\n",
      "avg / total       0.89      0.91      0.90      2368\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 0.997465\n",
      "Test Accuracy LOGISTIC: 0.886777\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.93      0.94      0.94      2165\n",
      "          -       0.32      0.29      0.30       203\n",
      "\n",
      "avg / total       0.88      0.89      0.88      2368\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 0.999638\n",
      "Test Accuracy LOGISTIC: 0.870722\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.94      0.92      0.93      2165\n",
      "          -       0.28      0.32      0.30       203\n",
      "\n",
      "avg / total       0.88      0.87      0.87      2368\n",
      "\n",
      "Modelo para el skill: Business intelligence\n",
      "Usando C= 0.010000\n",
      "Training Accuracy LOGISTIC: 0.999819\n",
      "Test Accuracy LOGISTIC: 1.000000\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      1.00      1.00      2368\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2368\n",
      "\n",
      "Usando C= 0.100000\n",
      "Training Accuracy LOGISTIC: 0.999819\n",
      "Test Accuracy LOGISTIC: 1.000000\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      1.00      1.00      2368\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2368\n",
      "\n",
      "Usando C= 10.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 1.000000\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      1.00      1.00      2368\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2368\n",
      "\n",
      "Usando C= 100.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 1.000000\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      1.00      1.00      2368\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2368\n",
      "\n",
      "Usando C= 1000.000000\n",
      "Training Accuracy LOGISTIC: 1.000000\n",
      "Test Accuracy LOGISTIC: 1.000000\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      1.00      1.00      2368\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_skills = [29, 255, 8185]\n",
    "for skill in selected_skills:\n",
    "    print 'Modelo para el skill: {}'.format(skills_labels[skill])\n",
    "    ytr = Ztr[:,skill]\n",
    "    Xtr = csr_matrix(np.delete(Ztr.toarray(),skill,1))\n",
    "    yts = Zts[:,skill]\n",
    "    Xts = csr_matrix(np.delete(Zts.toarray(),skill,1))\n",
    "    model=do_LOGIT(Xtr, ytr.toarray()[:,0], Xts, yts.toarray()[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.847728\n",
      "Test Accuracy BernoulliNB: 0.799747\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.82      0.85      0.84      1443\n",
      "          -       0.76      0.72      0.74       925\n",
      "\n",
      "avg / total       0.80      0.80      0.80      2368\n",
      "\n",
      "Training Accuracy BernoulliNB: 0.927757\n",
      "Test Accuracy BernoulliNB: 0.895226\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.92      0.97      0.94      2165\n",
      "          -       0.27      0.13      0.18       203\n",
      "\n",
      "avg / total       0.87      0.90      0.88      2368\n",
      "\n",
      "Training Accuracy BernoulliNB: 0.999819\n",
      "Test Accuracy BernoulliNB: 1.000000\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      1.00      1.00      2368\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import random\n",
    "\n",
    "def do_NAIVE_BAYES(x,y,xt,yt):\n",
    "    model = BernoulliNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"BernoulliNB\")\n",
    "    return model\n",
    "\n",
    "#selected_skills = [639, 1594, 29]\n",
    "selected_skills = [29, 255, 8185]\n",
    "for skill in selected_skills:\n",
    "    ytr = Ztr[:,skill]\n",
    "    Xtr = csr_matrix(np.delete(Ztr.toarray(),skill,1))\n",
    "    yts = Zts[:,skill]\n",
    "    Xts = csr_matrix(np.delete(Zts.toarray(),skill,1))\n",
    "    model=do_NAIVE_BAYES(Xtr, ytr.toarray()[:,0], Xts, yts.toarray()[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy MULTINOMIAL: 0.844106\n",
      "Test Accuracy MULTINOMIAL: 0.789185\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.84      0.80      0.82      1443\n",
      "          -       0.71      0.77      0.74       925\n",
      "\n",
      "avg / total       0.79      0.79      0.79      2368\n",
      "\n",
      "Training Accuracy MULTINOMIAL: 0.930292\n",
      "Test Accuracy MULTINOMIAL: 0.866075\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.93      0.93      0.93      2165\n",
      "          -       0.22      0.22      0.22       203\n",
      "\n",
      "avg / total       0.87      0.87      0.87      2368\n",
      "\n",
      "Training Accuracy MULTINOMIAL: 0.994930\n",
      "Test Accuracy MULTINOMIAL: 0.987326\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      0.99      0.99      2368\n",
      "          -       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.99      0.99      2368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import random\n",
    "\n",
    "def do_MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"MULTINOMIAL\")\n",
    "    return model\n",
    "selected_skills = [29, 255, 8185]\n",
    "for skill in selected_skills:\n",
    "    ytr = Ztr[:,skill]\n",
    "    Xtr = csr_matrix(np.delete(Ztr.toarray(),skill,1))\n",
    "    yts = Zts[:,skill]\n",
    "    Xts = csr_matrix(np.delete(Zts.toarray(),skill,1))\n",
    "    model=do_MULTINOMIAL(Xtr, ytr.toarray()[:,0], Xts, yts.toarray()[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.879232\n",
      "Test Accuracy SVM: 0.831010\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.84      0.90      0.87      1443\n",
      "          -       0.82      0.73      0.77       925\n",
      "\n",
      "avg / total       0.83      0.83      0.83      2368\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.946587\n",
      "Test Accuracy SVM: 0.801859\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.83      0.85      0.84      1443\n",
      "          -       0.76      0.72      0.74       925\n",
      "\n",
      "avg / total       0.80      0.80      0.80      2368\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 0.985515\n",
      "Test Accuracy SVM: 0.760879\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.80      0.80      0.80      1443\n",
      "          -       0.69      0.69      0.69       925\n",
      "\n",
      "avg / total       0.76      0.76      0.76      2368\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 0.983705\n",
      "Test Accuracy SVM: 0.746937\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.79      0.79      0.79      1443\n",
      "          -       0.68      0.68      0.68       925\n",
      "\n",
      "avg / total       0.75      0.75      0.75      2368\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 0.977186\n",
      "Test Accuracy SVM: 0.733840\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.77      0.79      0.78      1443\n",
      "          -       0.67      0.64      0.65       925\n",
      "\n",
      "avg / total       0.73      0.73      0.73      2368\n",
      "\n",
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.943147\n",
      "Test Accuracy SVM: 0.923532\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.93      0.99      0.96      2165\n",
      "          -       0.71      0.18      0.29       203\n",
      "\n",
      "avg / total       0.91      0.92      0.90      2368\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.976281\n",
      "Test Accuracy SVM: 0.920997\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.93      0.98      0.96      2165\n",
      "          -       0.59      0.25      0.35       203\n",
      "\n",
      "avg / total       0.90      0.92      0.91      2368\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 0.997284\n",
      "Test Accuracy SVM: 0.867765\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.93      0.92      0.93      2165\n",
      "          -       0.26      0.29      0.27       203\n",
      "\n",
      "avg / total       0.87      0.87      0.87      2368\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 0.995655\n",
      "Test Accuracy SVM: 0.860161\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.93      0.91      0.92      2165\n",
      "          -       0.24      0.30      0.27       203\n",
      "\n",
      "avg / total       0.87      0.86      0.87      2368\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 0.993844\n",
      "Test Accuracy SVM: 0.855936\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.94      0.91      0.92      2165\n",
      "          -       0.25      0.33      0.28       203\n",
      "\n",
      "avg / total       0.88      0.86      0.87      2368\n",
      "\n",
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.999819\n",
      "Test Accuracy SVM: 1.000000\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      1.00      1.00      2368\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2368\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 1.000000\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      1.00      1.00      2368\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2368\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 1.000000\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      1.00      1.00      2368\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2368\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 1.000000\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      1.00      1.00      2368\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2368\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 1.000000\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       1.00      1.00      1.00      2368\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "def do_SVM(x,y,xt,yt):\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:\n",
    "        print \"El valor de C que se esta probando: %f\"%C\n",
    "        model = LinearSVC(C=C)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "selected_skills = [29, 255, 8185]\n",
    "for skill in selected_skills:\n",
    "    ytr = Ztr[:,skill]\n",
    "    Xtr = csr_matrix(np.delete(Ztr.toarray(),skill,1))\n",
    "    yts = Zts[:,skill]\n",
    "    Xts = csr_matrix(np.delete(Zts.toarray(),skill,1))\n",
    "    do_SVM(Xtr, ytr.toarray()[:,0], Xts, yts.toarray()[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
