{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 1 G comparacion de LDA, QDA y KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "train_data_url = \"http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/vowel.train\"\n",
    "test_data_url = \"http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/vowel.test\"\n",
    "train_data_f = urllib.urlretrieve(train_data_url, \"train_data.csv\")\n",
    "test_data_f = urllib.urlretrieve(test_data_url, \"test_data.csv\")\n",
    "train_df = pd.DataFrame.from_csv('train_data.csv',header=0,index_col=0)\n",
    "test_df = pd.DataFrame.from_csv('test_data.csv',header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = train_df.ix[:,'x.1':'x.10'].values\n",
    "y = train_df.ix[:,'y'].values\n",
    "X_std = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68371212121212122, 0.98863636363636365, 0.93181818181818177]\n",
      "[0.45238095238095238, 0.41558441558441561, 0.49134199134199136]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.lda import LDA\n",
    "from sklearn.qda import QDA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "Xtest = test_df.ix[:,'x.1':'x.10'].values\n",
    "ytest = test_df.ix[:,'y'].values\n",
    "X_std_test = StandardScaler().fit_transform(Xtest)\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "models = {\n",
    "    0: LDA(),\n",
    "    1: QDA(),\n",
    "    2: KNeighborsClassifier(n_neighbors=10)\n",
    "}\n",
    "\n",
    "for i in range(3):\n",
    "    model = models[i]\n",
    "    model.fit(X_std,y)\n",
    "    train_scores.append(model.score(X_std,y))\n",
    "    test_scores.append(model.score(X_std_test,ytest))\n",
    "\n",
    "print train_scores\n",
    "print test_scores\n",
    "\n",
    "bar_width = 0.35\n",
    "index = np.arange(3)\n",
    "labels = ('LDA', 'QDA', 'KNN')\n",
    "rects1 = plt.bar(index, train_scores, bar_width, alpha = 0.5, color='b',label='Training set')\n",
    "rects2 = plt.bar(index + bar_width, test_scores, bar_width, alpha = 0.5, color='g',label='Testing set')\n",
    "\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Scores by model and set')\n",
    "plt.xticks(index + bar_width, labels)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparacion de técnicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al comparar las técnicas se observa que QDA tiene mejores resultados en el training set con una precisión de 0.988, sin embargo, a su vez es el modelo que peor precision alcanza con el testing set, llegando a un valor de 0.412. Por lo que se infiere que el modelo esta sobre ajustado. Por otra parte el modelo KNN se comporta mejor sobre el conjunto de test alcanzando casi un 50% de precisión (0.49). Es importante destacar que a pesar de que los modelos testeados tienden a sobre-ajustarse, la mayor precisión alcanzada según la información entregada por los investigadores es de un 54%.\n",
    "\n",
    "#TODO: BUSCAR linear classifiers vs non linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variación de K en modelo KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_score = []\n",
    "test_score = []\n",
    "kmax = 100\n",
    "for i in range(1,kmax):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn_model.fit(X_std,y)\n",
    "    train_score.append(knn_model.score(X_std,y))\n",
    "    test_score.append(knn_model.score(X_std_test,ytest))\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('KNN Accuracy')\n",
    "plt.plot(range(1,kmax),train_score,'-b.')\n",
    "plt.plot(range(1,kmax),test_score,'-g.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Se observa que al aumentar K la precisión del modelo tiende a disminuir. De este análisis se puede inferir que, es posible que en el espacio 11 dimensional en el que se representa la data las distintas clases estan superpuestas unas con otras. Esto, debido a que la precisión baja drásticamente al considerar 40 vecinos que es aporximadamente un 8% del set de datos. Otra situación que puede explicar esta baja de precisión, es que al considerar más vecinos se alcanzan regiones más lejanas del espacio 11 dimensional. Si se considerara un caso ideal en el que los ejemplos de una misma clase estan cercanos entre sí, y alejados a la vez de las otras clases. El abarcar mas ejemplos y por lo tanto, abarcar una proporción mayor  del espacio de representación explicaría aumento en el error de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
